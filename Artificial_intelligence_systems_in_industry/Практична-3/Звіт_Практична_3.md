# Практична робота 3

## Дизайн наукового експерименту, валідація, безпека та етика систем ШІ

**Дисципліна:** Системи штучного інтелекту в промисловості  
**Рівень:** PhD

---

## 1. Мета роботи

Набуття практичних навичок у:

- Проектуванні надійних експериментів для машинного навчання

- Проведенні статистичного порівняння алгоритмів

- Тестуванні моделей на стійкість до збурень (Robustness) та вразливість до атак (Adversarial Attacks)

- Оцінці етичних ризиків впровадження ШІ у промисловості

---

## 2. Опис датасету

**Джерело:** Синтетичний промисловий датасет, що моделює роботу турбіни/компресора.

| Параметр | Значення |
|----------|----------|
| Кількість зразків | 2000 |
| Кількість ознак | 3 |
| Розподіл класів | 50% / 50% (збалансований) |

### Ознаки датасету:

| Ознака | Опис | Одиниці вимірювання |
|--------|------|---------------------|
| Vibration | Рівень вібрації обладнання | мм/с |
| Temperature | Температура | °C |
| Pressure | Тиск | бар |

### Класи:
- **Клас 0 (Норма):** Нормальний режим роботи
- **Клас 1 (Аварія):** Аварійний/дефектний стан

### Описова статистика:

| Статистика | Vibration (mm/s) | Temperature (°C) | Pressure (bar) |
|------------|------------------|------------------|----------------|
| mean | 3.23 | 72.27 | 11.04 |
| std | 1.38 | 13.98 | 1.87 |
| min | 0.53 | 43.79 | 6.19 |
| max | 6.98 | 110.22 | 18.49 |

### Статистика по класах:

**Клас 0 (Норма):**

| Параметр | Vibration | Temperature | Pressure |
|----------|-----------|-------------|----------|
| mean | 2.03 | 59.97 | 10.05 |
| std | 0.49 | 5.04 | 0.98 |

**Клас 1 (Аварія):**

| Параметр | Vibration | Temperature | Pressure |
|----------|-----------|-------------|----------|
| mean | 4.44 | 84.57 | 12.03 |
| std | 0.82 | 7.93 | 2.01 |

---

## 3. Завдання 1: Підготовка даних та базове моделювання

### 3.1 Генерація даних

```python
def generate_industrial_data(n_samples=2000):
    # Нормальні дані (клас 0)
    X_normal = np.random.normal(
        loc=[2.0, 60.0, 10.0], 
        scale=[0.5, 5.0, 1.0], 
        size=(n_samples // 2, 3)
    )
    y_normal = np.zeros(n_samples // 2)
    
    # Аварійні дані (клас 1)
    X_fault = np.random.normal(
        loc=[4.5, 85.0, 12.0], 
        scale=[0.8, 8.0, 2.0], 
        size=(n_samples // 2, 3)
    )
    y_fault = np.ones(n_samples // 2)
    
    X = np.vstack((X_normal, X_fault))
    y = np.hstack((y_normal, y_fault))
    return X, y
```

### 3.2 Аналіз дисбалансу класів

| Клас | Кількість зразків | Відсоток |
|------|-------------------|----------|
| Норма (0) | 1000 | 50.0% |
| Аварія (1) | 1000 | 50.0% |
| **Співвідношення** | 1.00:1 | — |

**Висновок:** Класи збалансовані, спеціальні методи балансування не потрібні.

---

## 4. Завдання 2: Статистичне порівняння алгоритмів

### 4.1 Методологія

- **Крос-валідація:** StratifiedKFold з $k = 10$ фолдів
- **Метрика:** F1-Score (macro)
- **Алгоритми:** Logistic Regression, Gradient Boosting, Random Forest

```python
from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(model, X_scaled, y, cv=cv, scoring=f1_scorer)
```

### 4.2 Результати крос-валідації

| Модель | Середнє F1 | Std | Min | Max |
|--------|------------|-----|-----|-----|
| Logistic Regression (Baseline) | 0.9975 | 0.0025 | 0.9950 | 1.0000 |
| Gradient Boosting | 0.9965 | 0.0023 | 0.9950 | 1.0000 |
| **Random Forest** | **0.9985** | 0.0023 | 0.9950 | 1.0000 |

### 4.3 Статистичний тест

**Порівняння:** Logistic Regression vs Gradient Boosting

#### Тест Шапіро-Вілка на нормальність:

Нульова гіпотеза $H_0$: вибірка має нормальний розподіл.

| Модель | W-статистика | p-value | Висновок |
|--------|--------------|---------|----------|
| Logistic Regression | 0.6553 | 0.0003 | Ненормальний |
| Gradient Boosting | 0.5942 | 0.0000 | Ненормальний |

Оскільки $p < 0.05$ для обох розподілів — застосовуємо **непараметричний тест Вілкоксона**.

#### Тест Вілкоксона:

$$H_0: \text{Медіани двох вибірок рівні}$$

```python
from scipy import stats
result = stats.wilcoxon(scores_lr, scores_gb)
```

| Параметр | Значення |
|----------|----------|
| Статистика | 0.0000 |
| P-value | 0.5000 |

**Висновок:** При $p = 0.5 > 0.05$ немає підстав відхилити $H_0$. Різниця між алгоритмами **статистично незначуща**.

---

## 5. Завдання 3: Тестування на стійкість (Robustness & Security)

### 5.1 Архітектура нейронної мережі

```python
model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(3,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

| Шар | Output Shape | Параметри |
|-----|--------------|-----------|
| Dense | (None, 64) | 256 |
| Dropout | (None, 64) | 0 |
| Dense_1 | (None, 32) | 2,080 |
| Dense_2 | (None, 1) | 33 |
| **Всього** | — | **2,369** |

**Baseline Accuracy:** 100.00%

### 5.2 Тестування на Гаусівський шум

Імітація промислового шуму за формулою:

$$x_{noisy} = x + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)$$

```python
noise = np.random.normal(0, sigma, X_test.shape)
X_noisy = X_test + noise
```

| $\sigma$ (Sigma) | Accuracy | Падіння точності |
|------------------|----------|------------------|
| 0.00 | 1.0000 | +0.00% |
| 0.10 | 1.0000 | +0.00% |
| 0.20 | 1.0000 | +0.00% |
| 0.30 | 0.9925 | +0.75% |
| 0.50 | 0.9600 | +4.00% |
| 0.70 | 0.9250 | +7.50% |
| 1.00 | 0.8900 | +11.00% |

**Висновок:** Модель демонструє поступове зниження точності при збільшенні рівня шуму. При $\sigma = 1.0$ точність падає на 11%.

### 5.3 FGSM атака (Fast Gradient Sign Method)

Метод генерації змагальних прикладів за формулою:

$$X_{adv} = X + \epsilon \cdot \text{sign}(\nabla_x J(\theta, X, y))$$

де:
- $J$ — функція втрат (binary crossentropy)
- $\nabla_x J$ — градієнт втрат по відношенню до вхідних даних
- $\epsilon$ — сила атаки

```python
def fgsm_attack(model, inputs, labels, epsilon):
    inputs = tf.cast(inputs, tf.float32)
    labels = tf.cast(labels, tf.float32)
    
    with tf.GradientTape() as tape:
        tape.watch(inputs)
        prediction = model(inputs)
        loss = tf.keras.losses.binary_crossentropy(labels, prediction)
    
    gradient = tape.gradient(loss, inputs)
    signed_grad = tf.sign(gradient)
    adversarial_data = inputs + epsilon * signed_grad
    
    return adversarial_data
```

| $\epsilon$ | Accuracy | Падіння точності |
|------------|----------|------------------|
| 0.00 | 1.0000 | +0.00% |
| 0.05 | 1.0000 | +0.00% |
| 0.10 | 1.0000 | +0.00% |
| 0.20 | 0.9875 | +1.25% |
| 0.30 | 0.9750 | +2.50% |
| 0.50 | 0.8775 | +12.25% |
| 0.70 | 0.6275 | +37.25% |
| 1.00 | 0.3150 | +68.50% |

> [!WARNING]
> При $\epsilon = 1.0$ точність падає до 31.5% — модель практично втрачає здатність класифікувати!

### 5.4 Детальний аналіз атаки

Аналіз впливу атаки на фізичні показники (один зразок, $\epsilon = 0.5$):

| Показник | Оригінал | Атака | Різниця |
|----------|----------|-------|---------|
| Vibration (mm/s) | 2.40 | 3.09 | **+0.69** |
| Temperature (°C) | 51.92 | 58.91 | **+6.99** |
| Pressure (bar) | 8.95 | 9.88 | **+0.93** |

| Метрика | Чисті дані | Атаковані дані |
|---------|------------|----------------|
| Ймовірність аварії | 0.0000 | 0.0008 |
| Рішення | 0 (Норма) | 0 (Норма) |

> [!TIP]
> Зміни показників (температура +7°C, вібрація +0.69 мм/с) знаходяться в межах можливої похибки датчиків. Оператор може не помітити такої зміни!

### 5.5 Adversarial Training (Захист)

Метод захисту через додавання атакованих прикладів до навчальної вибірки:

```python
# Генерація атакованих даних
X_train_adv = fgsm_attack(model, X_train, y_train, epsilon=0.2)

# Об'єднання чистих та атакованих даних
X_combined = np.vstack((X_train, X_train_adv))
y_combined = np.hstack((y_train, y_train))

# Донавчання
model.fit(X_combined, y_combined, epochs=10, batch_size=32)
```

**Результати після Adversarial Training:**

| $\epsilon$ | До AT | Після AT | Покращення |
|------------|-------|----------|------------|
| 0.00 | 1.0000 | 1.0000 | +0.00% |
| 0.10 | 1.0000 | 1.0000 | +0.00% |
| 0.20 | 0.9875 | 0.9925 | **+0.50%** |
| 0.30 | 0.9750 | 0.9775 | **+0.25%** |
| 0.50 | 0.8775 | 0.9050 | **+2.75%** |

**Висновок:** Adversarial Training підвищує стійкість моделі до атак.

---

## 6. Завдання 4: Етичний аудит

### 6.1 SHAP Values аналіз

SHAP (SHapley Additive exPlanations) — метод пояснення прогнозів моделі на основі теорії ігор.

```python
import shap

background = X_train[:100]
explainer = shap.KernelExplainer(model.predict, background)
shap_values = explainer.shap_values(test_samples)
```

**SHAP values для окремих зразків:**

| Зразок | Vibration | Temperature | Pressure | Передбачення |
|--------|-----------|-------------|----------|--------------|
| 0 | -0.1674 | -0.2444 | -0.0483 | 0.0000 |
| 1 | -0.2198 | -0.1855 | -0.0538 | 0.0009 |
| 2 | 0.1389 | 0.2504 | 0.1502 | 0.9996 |
| 3 | 0.2823 | 0.2505 | 0.0071 | 1.0000 |
| 4 | -0.2566 | -0.1536 | -0.0498 | 0.0000 |

### Важливість ознак (середні |SHAP|):

| Ознака | Важливість |
|--------|------------|
| **Vibration (mm/s)** | **0.2207** |
| Temperature (°C) | 0.2052 |
| Pressure (bar) | 0.0659 |

**Найважливіша ознака:** Vibration (вібрація)

> [!NOTE]
> Це відповідає фізиці процесу — підвищена вібрація є першою ознакою зносу підшипників та механічних несправностей турбін.

### 6.2 Аналіз ризиків (Confusion Matrix)

```
              Predicted
              Норма    Аварія
Actual Норма    203       0
       Аварія    0       197
```

| Метрика | Значення |
|---------|----------|
| True Negative (TN) | 203 |
| True Positive (TP) | 197 |
| False Positive (FP) | 0 |
| False Negative (FN) | 0 |

### Метрики якості:

| Метрика | Значення | Формула |
|---------|----------|---------|
| Precision | 1.0000 | $\frac{TP}{TP + FP}$ |
| Recall | 1.0000 | $\frac{TP}{TP + FN}$ |
| Specificity | 1.0000 | $\frac{TN}{TN + FP}$ |

### 6.3 Аналіз етичних ризиків

| Тип помилки | Наслідок у промисловості |
|-------------|--------------------------|
| **False Positive (FP)** | Зупинка конвеєра, коли аварії немає. Втрати від простою. |
| **False Negative (FN)** | Пропущена реальна аварія. Випуск браку, пошкодження обладнання, ризик для персоналу. |

> [!CAUTION]
> У промисловому контексті **False Negative (FN) є критичнішим**, оскільки може призвести до випуску бракованої продукції, пошкодження обладнання та загрози безпеці персоналу.

---

## 7. Висновки

1. **Датасет:** Синтетичний промисловий датасет (2000 зразків, 3 ознаки) успішно створено для моделювання роботи турбіни/компресора.

2. **Порівняння алгоритмів:** 
   - Random Forest показав найкращий результат (F1 = 0.9985)
   - Статистичний тест Вілкоксона ($p = 0.5$) не виявив значущої різниці між Logistic Regression та Gradient Boosting

3. **Robustness:**
   - При Гаусівському шумі $\sigma = 1.0$ точність падає на 11%
   - FGSM атака з $\epsilon = 1.0$ знижує точність до 31.5%
   - Adversarial Training покращує стійкість на 2.75% при $\epsilon = 0.5$

4. **Інтерпретація (SHAP):**
   - Найважливіша ознака — Vibration (вібрація), що відповідає фізиці процесу

5. **Етика:**
   - Модель досягла ідеальних показників (Precision = Recall = 1.0)
   - У реальних умовах необхідно мінімізувати False Negative для забезпечення безпеки

---

## 8. Використані бібліотеки

```python
numpy==1.24+
pandas==2.0+
scikit-learn==1.3+
tensorflow==2.15+
scipy==1.11+
shap==0.43+
matplotlib==3.7+
seaborn==0.12+
```
