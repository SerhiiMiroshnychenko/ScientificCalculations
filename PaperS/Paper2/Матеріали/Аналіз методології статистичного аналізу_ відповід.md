<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# Аналіз методології статистичного аналізу: відповідні посилання для методів та тестів

Проведений аналіз фрагменту статті виявив комплексну методологію статистичного аналізу, що включає широкий спектр методів та тестів. Кожен з них має відповідне науково-технічне обґрунтування та практичну реалізацію у сучасних статистичних бібліотеках. Знайдені посилання підтверджують актуальність та доцільність застосованих підходів для забезпечення статистичної коректності дослідження.

## Попередня обробка та підготовка даних

### Завантаження та обробка даних

Початковий етап методології передбачає завантаження даних з CSV-файлу, що реалізується через функцію `pandas.read_csv()` [^8]. Цей метод забезпечує ефективне читання структурованих даних з можливістю автоматичного визначення типів даних, роздільників та інших параметрів файлу. Функція підтримує широкий спектр параметрів для налаштування процесу завантаження, включаючи обробку заголовків, пропущених значень та кодування символів [^8].

Обробка пропущених значень здійснюється за допомогою методу `fillna()` [^9]. Цей підхід дозволяє замінювати NULL значення специфікованими величинами, що є критично важливим для забезпечення цілісності даних та подальшого статистичного аналізу [^9]. Метод надає можливість заміни значень як для окремих стовпців, так і для всього набору даних, з підтримкою різних стратегій заповнення.

### Розподіл даних на вибірки

Стратифіковане розбиття даних на тренувальну та тестову вибірки реалізується через функцію `train_test_split()` [^10]. Цей метод забезпечує збереження пропорційного розподілу цільової змінної в обох вибірках, що є особливо важливим для збалансованого навчання моделей та об'єктивної оцінки їх ефективності [^10]. Функція підтримує параметри для контролю розміру вибірок, випадкового стану та стратифікації.

## Аналіз нормальності розподілу

### Тест Шапіро-Вілка

Тест Шапіро-Вілка представлений у документації SciPy як `scipy.stats.shapiro()` [^4] та детально описаний у українських джерелах [^19][^20]. Цей тест призначений для перевірки нульової гіпотези про те, що дані походять з нормального розподілу [^4][^19]. Тест є особливо ефективним для малих вибірок (менше 50 спостережень) та вважається одним з найточніших методів перевірки нормальності [^19][^20]. Статистика тесту має значення від 0 до 1, причому значення близькі до 1 вказують на відповідність нормальному розподілу [^19].

### Тест Д'Агостіно-Пірсона

Узагальнений тест Д'Агостіно-Пірсона на нормальність розподілу реалізований як `scipy.stats.normaltest()` [^5]. Цей омнібус-тест поєднує оцінки асиметрії та ексцесу для створення комплексної перевірки нормальності [^5]. Тест базується на D'Agostino and Pearson omnibus normality test [^2] та є ефективним для виявлення різних типів відхилень від нормального розподілу.

### Тест Андерсона-Дарлінга

Критерій Андерсона-Дарлінга доступний через `scipy.stats.anderson()` [^6] та детально описаний у наукових джерелах [^3]. Цей непараметричний критерій згоди призначений для перевірки гіпотез про відповідність емпіричного розподілу теоретичному закону [^3]. Тест використовує статистику, що враховує відхилення у хвостах розподілу, що робить його особливо чутливим до екстремальних значень [^3][^6].

## Статистичний аналіз значущості ознак

### Параметричні методи

Для нормально розподілених даних застосовується t-тест, який реалізований як `scipy.stats.mstats.ttest_ind()` [^7]. Цей тест дозволяє порівнювати середні значення двох незалежних вибірок з можливістю урахування як рівних, так і нерівних дисперсій [^7]. Тест підтримує односторонні та двосторонні альтернативні гіпотези.

Коефіцієнт Cohen's d використовується для оцінки розміру ефекту [^11]. Цей показник стандартизує різницю між групами та інтерпретується згідно з загальноприйнятими критеріями: 0.2 - малий ефект, 0.5 - середній ефект, 0.8 - великий ефект [^11]. Коефіцієнт розраховується як різниця середніх, поділена на об'єднане стандартне відхилення.

### Непараметричні методи

Mann-Whitney U тест реалізований як `scipy.stats.mstats.mannwhitneyu()` [^12] та застосовується для ненормально розподілених даних. Цей тест порівнює медіани двох незалежних груп без припущень про нормальність розподілу [^12]. Тест автоматично обробляє пропущені значення та підтримує коригування на безперервність.

Показник AUC (Area Under Curve) для оцінки розміру ефекту обчислюється через `sklearn.metrics.roc_auc_score()` [^13]. Цей метрик вимірює площу під ROC-кривою та забезпечує оцінку здатності моделі розрізняти між класами [^13].

## Метрики оцінки ефективності моделі

### Базові метрики точності

Точність (accuracy) розраховується за допомогою `sklearn.metrics.accuracy_score()` [^18]. Цей показник визначає частку правильно класифікованих зразків від загальної кількості [^18]. Збалансована точність (balanced accuracy) обчислюється через `sklearn.metrics.balanced_accuracy_score()` [^14] та представляє середнє значення чутливості (recall) для кожного класу, що особливо важливо для незбалансованих наборів даних [^14].

### Комплексні метрики

Прецизійність (precision), повнота (recall) та F1-міра розраховуються одночасно через `sklearn.metrics.precision_recall_fscore_support()` [^15]. Прецизійність визначається як відношення істинно позитивних результатів до суми істинно позитивних та хибно позитивних, тоді як повнота представляє відношення істинно позитивних до суми істинно позитивних та хибно негативних [^15]. F1-міра є гармонічним середнім прецизійності та повноти.

### Специфічність та ROC-аналіз

Специфічність (specificity) може бути обчислена з матриці помилок як recall негативного класу [^16]. Цей показник вимірює здатність моделі правильно ідентифікувати негативні випадки. ROC-крива будується за допомогою `sklearn.metrics.roc_curve()` [^17], що дозволяє візуалізувати співвідношення між чутливістю та специфічністю при різних порогових значеннях.

## Висновки

Запропонована методологія демонструє комплексний підхід до статистичного аналізу, що включає сучасні методи обробки даних, тестування нормальності та оцінки ефективності моделей. Кожен компонент методології має надійне науково-технічне обґрунтування та практичну реалізацію у провідних статистичних бібліотеках Python, що забезпечує відтворюваність та валідність результатів дослідження. Використання автоматичного вибору між параметричними та непараметричними методами на основі тестів нормальності підвищує статистичну коректність аналізу та методологічну гнучкість підходу.

<div style="text-align: center">⁂</div>

[^1]: https://www.youtube.com/watch?v=IEoqbZydHuo

[^2]: https://www.multitran.com/m.exe?a=3\&l1=2\&l2=1\&s=обобщённый+тест+Д'Агостино-Пирсона+на+нормальность+распределения

[^3]: https://ru.wikipedia.org/wiki/Критерий_%D0%90%D0%BD%D0%B4%D0%B5%D1%80%D1%81%D0%BE%D0%BD%D0%B0_%E2%80%94_%D0%94%D0%B0%D1%80%D0%BB%D0%B8%D0%BD%D0%B3%D0%B0

[^4]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html

[^5]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html

[^6]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html

[^7]: https://docs.scipy.org/doc/scipy-1.15.2/reference/generated/scipy.stats.mstats.ttest_ind.html

[^8]: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html

[^9]: https://www.w3schools.com/python/pandas/ref_df_fillna.asp

[^10]: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html

[^11]: https://resources.nu.edu/statsresources/cohensd

[^12]: https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.stats.mstats.mannwhitneyu.html

[^13]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html

[^14]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html

[^15]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html

[^16]: https://stackoverflow.com/questions/33275461/specificity-in-scikit-learn

[^17]: http://lijiancheng0614.github.io/scikit-learn/modules/generated/sklearn.metrics.roc_curve.html

[^18]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html

[^19]: https://bishche.home.cx.ua/shho-take-test-shapiro-vilka-v-anova/

[^20]: https://ukrayinska.libretexts.org/Статистика/Прикладна_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0/%D0%9A%D0%BD%D0%B8%D0%B3%D0%B0:_%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8_%D0%B7_R_-_%D0%9F%D1%96%D0%B4%D1%80%D1%83%D1%87%D0%BD%D0%B8%D0%BA_%D0%B4%D0%BB%D1%8F_%D1%81%D1%82%D1%83%D0%B4%D0%B5%D0%BD%D1%82%D1%96%D0%B2_%D0%BF%D1%81%D0%B8%D1%85%D0%BE%D0%BB%D0%BE%D0%B3%D1%96%D1%97_%D1%82%D0%B0_%D1%96%D0%BD%D1%88%D0%B8%D1%85_%D0%BF%D0%BE%D1%87%D0%B0%D1%82%D0%BA%D1%96%D0%B2%D1%86%D1%96%D0%B2_(Navarro)/13:_%D0%9F%D0%BE%D1%80%D1%96%D0%B2%D0%BD%D1%8F%D0%BD%D0%BD%D1%8F_%D0%B4%D0%B2%D0%BE%D1%85_%D0%B7%D0%B0%D1%81%D0%BE%D0%B1%D1%96%D0%B2/13.09:_%D0%9F%D0%B5%D1%80%D0%B5%D0%B2%D1%96%D1%80%D0%BA%D0%B0_%D0%BD%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%96_%D0%B7%D1%80%D0%B0%D0%B7%D0%BA%D0%B0

[^21]: https://uk.eitca.org/tag/shapiro-wilk-test/

[^22]: https://uk.wikipedia.org/wiki/Критерій_%D0%BD%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%96

[^23]: https://blacknick.info/index.php?subj=stat07

[^24]: https://docs.scipy.org/doc/scipy-1.15.0/tutorial/stats/hypothesis_shapiro.html

[^25]: https://tec.citius.usc.es/stac/doc/scipy.stats.shapiro.html

[^26]: https://sky.pro/wiki/python/chtenie-opredelyonnykh-kolonok-csv-bez-zagolovkov-v-pandas/

[^27]: https://pythonworld.ru/obrabotka-dannyx/pandas-cookbook-1-csv-reading.html

[^28]: https://pythonru.com/baza-znanij/sklearn-train-test-split

[^29]: https://scikit-learn.org/0.20/modules/generated/sklearn.model_selection.train_test_split.html

[^30]: https://neptune.ai/blog/balanced-accuracy

[^31]: https://www.blog.trainindata.com/a-data-scientists-guide-to-balanced-accuracy/

[^32]: https://sparkbyexamples.com/pandas/pandas-dataframe-clip-method/

[^33]: https://matplotlib.org/2.1.2/api/_as_gen/matplotlib.pyplot.hist.html

[^34]: https://stepik.org/lesson/1458877/step/1

[^35]: https://sky.pro/wiki/python/ocenka-modelej-s-ispolzovaniem-scikit-learn/

[^36]: https://ru.statisticseasily.com/как-найти-коэнов-д/

[^37]: https://support.microsoft.com/uk-ua/office/t-test-функція-t-test-d4e08ec3-c545-485f-962e-276f7cbed055

[^38]: https://stackoverflow.com/questions/52774385/how-to-input-data-for-shapiro-wilk-test-using-python-scipy

[^39]: https://stackoverflow.com/questions/74421173/how-does-the-scipy-stats-shapiro-calculate-a-test-statistic

[^40]: https://www.statology.org/shapiro-wilk-test-python/

[^41]: https://stackoverflow.com/questions/12838993/scipy-normaltest-how-is-it-used

[^42]: https://www.w3schools.com/python/pandas/pandas_csv.asp

[^43]: https://www.datacamp.com/tutorial/pandas-read-csv

[^44]: https://pandas.pydata.org/pandas-docs/version/0.24.0rc1/api/generated/pandas.read_csv.html

[^45]: https://www.w3resource.com/python-exercises/pandas/pandas-detect-outliers-in-a-dataframe-using-the-iqr-method.php

[^46]: https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.fillna.html

[^47]: https://www.kdnuggets.com/how-to-handle-outliers-in-dataset-with-pandas

[^48]: https://pandas.pydata.org/docs/dev/reference/api/pandas.read_csv.html

[^49]: https://docs.vultr.com/python/third-party/pandas/read_csv

[^50]: https://habr.com/ru/companies/otus/articles/797283/

[^51]: https://processingjs.rozh2sch.org.ua

[^52]: https://ru.hexlet.io/qna/data-analytics/questions/kak-zapolnit-propuski-mediannym-znacheniem-pandas

[^53]: http://eprints.zu.edu.ua/40845/1/PraktykumAI.pdf

[^54]: https://stackoverflow.com/questions/34842405/parameter-stratify-from-method-train-test-split-scikit-learn

[^55]: https://scikit-learn.ru/stable/modules/generated/sklearn.model_selection.train_test_split.html

[^56]: https://code.likeagirl.io/good-train-test-split-an-approach-to-better-accuracy-91427584b614

[^57]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3840331/

[^58]: https://www.statology.org/balanced-accuracy-python-sklearn/

[^59]: https://www.thesecuritybuddy.com/python-scikit-learn/calculate-specificity-using-sklearn-in-python/

[^60]: https://stackoverflow.com/questions/75995485/in-sklearn-how-to-obtain-balanced-accuracy-for-every-class-in-a-multi-class-task

[^61]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html

[^62]: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html

[^63]: https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.clip_lower.html

[^64]: https://stackoverflow.com/questions/74109573/is-it-possible-to-clip-and-fill-other-value-with-nan-in-pandas

[^65]: https://pandas.pydata.org/pandas-docs/version/1.2/reference/api/pandas.DataFrame.clip.html

[^66]: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html

[^67]: https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.clip.html

[^68]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html

[^69]: https://scikit-learn.ru/stable/modules/generated/sklearn.metrics.accuracy_score.html

[^70]: https://www.educative.io/answers/what-is-the-accuracyscore-function-in-sklearn

[^71]: https://stackoverflow.com/questions/37659970/how-does-sklearn-compute-the-precision-score-metric

[^72]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html

[^73]: https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.metrics.f1_score.html

[^74]: https://scikit-learn.org/stable/modules/model_evaluation.html

