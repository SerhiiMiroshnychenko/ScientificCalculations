 # АВТОМАТИЗОВАНА ОПТИМІЗАЦІЯ ВІДБОРУ ОЗНАК У ГРАДІЄНТНОМУ БУСТИНГУ ДЛЯ B2B ПРОГНОЗУВАННЯ
 
 ## АНОТАЦІЯ
 
 У роботі запропоновано підхід до автоматизованого відбору ознак у моделях градієнтного бустингу XGBoost
для прогнозування успішності замовлень у сегменті B2B електронної комерції. Дослідження спирається на два
репрезентативні датасети зі 86,794 спостереженнями кожен, що містять 24 бізнес-індикатори та цільову бінарну
змінну успішності замовлення. Запропоновано шість стратегій відбору ознак — прямий та зворотний відбір за
важливістю XGBoost, прямий та зворотний жадібні алгоритми, рекурсивне виключення ознак (RFE) та Boruta.
Для кожної стратегії здійснено 100-кратну оптимізацію гіперпараметрів за допомогою Optuna з використанням
Tree-Structured Parzen Estimator та метрики AUC-PR. Результати показали, що жадібні алгоритми забезпечують
найвищі значення AUC-PR (0.9787 та 0.9778 для двох датасетів відповідно) при оптимальному наборі 16 ознак,
зменшуючи розмірність на 33%. Доведено стабільність дев’яти критичних предикторів,
що входять до найкращих наборів усіма методами на обох вибірках. Запропонована методика поєднує відбір
ознак з байєсівською оптимізацією гіперпараметрів, що забезпечує статистично значуще підвищення AUC-PR
на 0.35 – 0.37% порівняно з базовими моделями та знижує кількість помилкових класифікацій у 2.7 – 3.7% випадків.
Викладені результати формують підґрунтя для впровадження інтерпретованих, обчислювально ефективних систем
прогнозування в B2B логістиці та управлінні запасами.  

Ключові слова: Автоматизований відбір ознак, градієнтний бустинг, XGBoost, B2B прогнозування, машинне навчання, зменшення розмірності, AUC-PR.

## ВСТУП

Стрімке зростання електронної комерції у сегменті B2B трансформує традиційні моделі взаємодії між постачальниками й клієнтами,
ускладнюючи управління ланцюгами постачання і запасами https://dl.acm.org/doi/10.1145/3647750.3647754, https://doi.org/10.1007/s43069-022-00166-4. 
Точне прогнозування у сегменті Business-to-Business (B2B) є критично важливим для стратегічного планування,
ефективного управління ресурсами та оптимізації операцій, дозволяючи компаніям оперативно реагувати на
динамічні ринкові тенденції https://doi.org/10.54691/bcpbm.v36i.3487.
Оптимізація виробничих процесів підприємства вимагає забезпечення адекватних запасів продукції,
координації виробничих циклів та ефективного управління постачанням сировини.
Ключовою умовою досягнення цих цілей є прогнозування обсягів продукції та сировини на складських потужностях.
Згідно з дослідженням https://doi.org/10.30525/978-9934-26-506-8-133, прогнозування складських запасів традиційно
базується на затверджених замовленнях. Однак значний часовий лаг між ініціацією та затвердженням замовлень
створює необхідність розробки моделей машинного навчання для прогнозування ймовірності успішної реалізації 
замовлень на основі історичних даних.
Точне прогнозування ймовірності успішного виконання замовлення дає змогу скоротити фінансові ризики,
мінімізувати надлишкові запаси та підвищити рівень обслуговування клієнтів
https://www.semanticscholar.org/paper/Applying-Machine-Learning-Techniques-to-Forecast-Heino/d17599a4ebc651fd29997c4f2f5f10e0b905e9a4,
https://www.semanticscholar.org/paper/EWM-based-Comprehensive-Evaluation-of-Regional-in-Su-Xue/a2a518944db11a61c622754fcb816fd983cbb571

Алгоритм Extreme Gradient Boosting https://dl.acm.org/doi/10.1145/2939672.2939785 зарекомендував себе як один із найефективніших
методів для подібних завдань https://doi.org/10.1109/ICTEST64710.2025.11042705, https://pmc.ncbi.nlm.nih.gov/articles/PMC10121810/,
https://www.tandfonline.com/doi/full/10.1080/1206212X.2024.2431874, 
однак його продуктивність значною мірою залежить від релевантності набору ознак і
налаштувань моделі https://doi.org/10.1016/j.eswa.2021.115895, https://pubmed.ncbi.nlm.nih.gov/39381765/,
https://ieeexplore.ieee.org/document/10543523, https://ieeexplore.ieee.org/document/10913271, https://doi.org/10.35882/jeeemi.v5i4.322.

Сучасні ERP системи накопичують величезні обсяги даних про поведінку клієнтів, характеристики замовлень та результати бізнес-процесів.
Високовимірний простір ознак призводить до «прокляття розмірності» https://pmc.ncbi.nlm.nih.gov/articles/PMC9580915/,
збільшує час тренування, ускладнює інтерпретацію та підвищує ризик перенавчання https://dx.doi.org/10.2139/ssrn.5154947.
Це створює необхідність відбору найбільш інформативних ознак https://doi.org/10.3390/math8091590,
https://www.nature.com/articles/s41598-023-49962-w, https://doi.org/10.3389/fbinf.2022.927312.

Вибір оптимального методу відбору ознак є критично важливим для ефективності моделей бінарної класифікації,
особливо у контексті високовимірних даних B2B замовлень.
Фундаментальна проблема відбору ознак полягає в тому, що кількість можливих підмножин ознак зростає експоненціально
з кількістю доступних ознак https://www.tandfonline.com/doi/abs/10.1080/00949658208810560, https://ieeexplore.ieee.org/document/7115942.

Недоцільність та виключну ресурсоємність повного
повного перебору ознак підкреслено в наступних роботах:
https://doi.org/10.1016/S0004-3702(97)00063-5,
https://doi.org/10.3233/IDA-1997-1302,
https://doi.org/10.1214/15-AOS1388.

Chen та колеги підкреслюють, що "визначення ідеальної підмножини ознак зі списку можливостей є комбінаторною проблемою,
яка не може бути вирішена при високій розмірності без використання специфічних припущень або компромісів"
https://doi.org/10.1186/s40537-020-00327-4. Ця експоненціальна складність робить необхідним використання евристичних
алгоритмів для знаходження субоптимальних, але практично прийнятних рішень.

Дослідження демонструють, що різні підходи до відбору
ознак мають специфічні переваги залежно від характеристик даних та цільових метрик оптимізації https://doi.org/10.1093/bib/bbx124,
https://doi.org/10.1186/s12859-020-3361-9, https://doi.org/10.1093/bioinformatics/btm344.

Метою дослідження є визначення оптимальної стратегії відбору ознак для прогнозування успішності B2B замовлень
 з використанням XGBoost в поєднанні з автоматизованою оптимізацією гіперпараметрів.

Для досягнення поставленої мети визначено наступні завдання дослідження:

	1. Порівняти ефективність шести різних методів відбору ознак
    
	2. Визначити оптимальний розмір набору ознак для досліджуваних даних
    
	3. Ідентифікувати найбільш інформативні характеристики B2B замовлень
    
	4. Розробити практичні рекомендації для впровадження у виробничі системи
	
## МЕТОДИ ТА МЕТОДИКИ ДОСЛІДЖЕННЯ

2.1 ПІДГОТОВКА ДАНИХ

Дослідження базується на двох незалежних наборах історичних даних про успішність B2B замовлень.
Для забезпечення репрезентативності та збалансованості аналізу розміри обох датасетів було стандартизовано
до  86 794 записів, що містять інформацію про замовлення з 24 характеристиками
(ознаками). Цільова змінна (is_successful) характеризує успішність замовлення – дорівнює 1 у випадку схваленого та успішного
виконаного, або 0 в іншому випадку. 
Розподіл цільових класів: 54 763 успішних замовлення (клас 1) та 32 031 неуспішне замовлення (клас 0),
що відповідає співвідношенню приблизно 63:37.

Структура даних включає:

- **Характеристики замовлення:** 
	кількість повідомлень в замовленні (order_messages),
	сума замовлення (order_amount),
	кількість змін в замовленні (order_changes), 
	кількість позицій (order_lines_count),
	джерело замовлення (source),
	менеджер що обробляє замовлення (salesperson),
	знижка в замовленні (discount_total),
    
- **Темпоральні ознаки:** 
	вік замовлення від початку діяльності компанії в місяцях (create_date_months), 
	квартал, місяць, день тижня та година доби коли зроблено замовлення (quarter, month, day_of_week, hour_of_day), 
    
- **Агреговані показники клієнта:** 
	відсоток успішних замовлень у клієнта (partner_success_rate),
	загальна кількість замовлень клієнта (partner_total_orders),
	строк співпраці з клієнтом в днях (partner_order_age_days),
	загальна кількість повідомлень клієнта (partner_total_messages),
	середня сума в замовленнях клієнта (partner_avg_amount),
	середня кількість змін в замовленнях у клієнта (partner_avg_changes),
	середні значення сум, повідомлень, змін для успішних та неуспішних замовлень клієнта 
	(partner_success_avg_amount,partner_fail_avg_amount,partner_success_avg_messages,partner_fail_avg_messages,partner_success_avg_changes,partner_fail_avg_changes)

Відсутні дані оброблено шляхом заповнення медіаною для забезпечення стійкості до екстремальних значень https://doi.org/10.46810/tdfd.1460871.

Негативні значення замінено на нуль у випадках,
коли від'ємні величини не мають фізичної чи економічної інтерпретації https://doi.org/10.4236/oalib.1106619, https://doi.org/10.15588/1607-3274-2022-3-5.

Викиди виявлено за критерієм 1,5 міжквартильного розмаху (IQR) https://doi.org/10.15157/IJITIS.2022.5.3.971-1005
та оброблено методом вінсоризації https://www.msci.com/eqb/methodology/meth_docs/MSCI_GIMIVGMethod_Feb2021.pdf
для збереження всіх спостережень при мінімізації впливу відхилень. 

Числові ознаки нормалізовано за допомогою Robust Scaler,
що як показано в https://doi.org/10.3390/technologies9030052 підвищує стабільність і точність
моделей у порівнянні зі стандартним масштабуванням. . 

Циклічні часові індикатори трансформовано синусоїдальними та косинусоїдальними перетвореннями https://doi.org/10.1080/19401493.2018.1498538,
https://feature-engine.trainindata.com/en/1.8.x/user_guide/creation/CyclicalFeatures.html, 
категоріальні змінні закодовано методом OHE Extended Compact https://doi.org/10.1007/978-981-13-6661-1_6.

Дисбаланс класів компенсовано параметром scale_pos_weight https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html#handle-imbalanced-dataset. 

Дані розподілено на навчальну та тестову вибірки у співвідношенні 70:30 із стратифікованим розбиттям 
для збереження пропорції цільової змінної 
(22.	Särndal C.-E., Swensson B., Wretman J. Model Assisted Survey Sampling (Springer Series in Statistics). Springer, 2003. 694 p.). 

Генератор псевдовипадкових чисел зафіксовано параметром random_state=42
для забезпечення повторюваності результатів https://doi.org/10.1109/msp.2022.3217659.

2.2 ЕКСПЕРЕМЕНТАЛЬНА СИСТЕМА

Дослідження реалізовано через комплексний підхід, 
побудований за принципом послідовного покращення якості моделі через три основні етапи.

На першому етапі проведено базове тестування моделі XGBoost із стандартними параметрами на
повному наборі ознак для встановлення початкового рівня якості.

Другий етап присвячений оптимізації гіперпараметрів за допомогою фреймворку Optuna
з алгоритмом Tree-structured Parzen Estimator https://ui.adsabs.harvard.edu/link_gateway/2023arXiv230517094F/doi:10.48550/arXiv.2305.17094,
який показав високу якість оптимізації гіперпараметрів XGBoost https://ieeexplore.ieee.org/document/10872404, 
https://www.sciencedirect.com/science/article/abs/pii/S0301479725020298?via%3Dihub,
та був визначений як найбільш ефективний алгоритм в [посилання на статтю в MIP]. 
Простір пошуку включав дев'ять ключових гіперпараметрів XGBoost https://xgboost.readthedocs.io/en/latest/parameter.html, 

 кількість дерев (100-1000),
 швидкість навчання (0.01-0.35),
 максимальна глибина (3-12),
 мінімальна вага дочірнього вузла (1-10),
 gamma-параметр (0-2.0),
 параметри субвибірки (0.6-1.0)
 та регуляризації (L1: 0-1.5, L2: 0.1-3.0).

Цільова функція базувалася на 5-кратній крос-валідації https://doi.org/10.1109/tensymp61132.2024.10752215, 
з метрикою Area Under Precision-Recall Curve (AUC-PR), що зарекомендувала себе як найбільш придатна
для оцінювання ефективності бінарної класифікації у контексті незбалансованих даних в багатьох дослідженнях:
 https://doi.org/10.1111/2041-210x.13140, https://doi.org/10.1109/ICMLA58977.2023.00335, https://doi.org/10.23919/ICACS.2019.8689135, 
https://doi.org/10.1111/2041-210X.13140, https://doi.org/10.1016/j.patter.2024.100994, https://doi.org/10.1109/ICTAI62512.2024.00028,
https://doi.org/10.1111/2041-210X.14071. 
Оптимізація проводилася протягом 100 ітерацій.

Третій етап включає реалізацію та порівняння шести різних методів відбору ознак з використанням
оптимізованих гіперпараметрів, знайдених на попередньому етапі.
Для вирішення поставленої задачі було розроблено програмний комплекс,
який реалізує повний цикл порівняння шести підходів до відбору ознак.

**Прямий відбір за важливістю XGBoost.** Вбудований метод, що використовує внутрішні метрики важливості XGBoost для ранжування ознак https://dl.acm.org/doi/10.1145/2939672.2939785. Алгоритм послідовно додає ознаки від найважливішої до найменш важливої на основі показників gain, weight, cover https://xgboost.readthedocs.io/en/stable/python/python_api.html.
Актуальні дослідження доводять, що додавання ознак у порядку зростання gain-метрики XGBoost
дозволяє отримати ранні «плато» точності, коли подальше розширення простору вже не покращує F-міру.
Для мереж «розумної» енергетики та смарт-ґридів такий підхід знизив час тренування майже на третину
без втрати якості https://doi.org/10.3390/su151713146
Попри популярність цього методу завдяки його інтеграції у сам алгоритм XGBoost,
його обмеженням є схильність до переоцінювання ознак із великою дисперсією або високою кореляцією.
У дослідженні Demir & Sahin (2023) було показано, що поєднання XGBoost з Recursive Feature Elimination та Boruta
дозволяє досягти стабільнішої продуктивності,
ніж при застосуванні лише вагової важливості (https://doi.org/10.1007/s00521-022-07856-4).

**Зворотний відбір за важливістю XGBoost.** Протилежний підхід, що починається з повного набору ознак та
 ітеративно видаляє найменш важливі. Метод ефективно зменшує упередженість традиційних метрик важливості
 XGBoost, особливо у випадках з корельованими предикторами 
https://doi.org/10.1016/j.bja.2025.01.022.

**Жадібний прямий відбір (Greedy Forward Selection, GFS).** Обгортковий метод, що починається з порожнього набору
та додає ознаку з максимальним покращенням цільової метрики на кожному кроці.
Теоретичне обґрунтування конвергенції представлено у класичних роботах https://www.jstor.org/stable/2684436?origin=crossref,
 https://www.jstor.org/stable/2346865?origin=crossref. 

Сучасні варіації методу включають паралельний алгоритм для великих даних https://link.springer.com/article/10.1007/s10994-018-5748-7,
метаевристичний підхід для аналізу тексту https://doi.org/10.1016/j.eswa.2020.113176,
спеціалізований алгоритм для систем ранжування https://ieeexplore.ieee.org/abstract/document/5960053
 та модифікації для задач з обмеженим бюджетом https://doi.org/10.1186/s12859-020-3361-9.
 Гібридний підхід з PSO демонструє покращення точності та зменшення підмножини ознак https://doi.org/10.1007/s41060-024-00712-9. 
Основне обмеження полягає у локальній природі пошуку https://doi.org/10.3390/electronics10161973.

**Жадібний зворотний відбір (Greedy Backward Elimination, GBE).** Стартує з повного набору та видаляє ознаку
 з найменшим впливом на продуктивність [Draper, N. and Smith, H. (1966) Applied Regression Analysis. John Wiley & Sons, New York].
Ефективний для оптимізації моделей з високою початковою розмірністю, як продемонстровано для прогнозування деформації
 незв'язаних агрегатів https://doi.org/10.1016/j.cscm.2023.e02554.

**Рекурсивне виключення ознак (Recursive Feature Elimination, RFE).** Обгортковий алгоритм, що поєднує зворотне
 видалення з повторним перенавчанням моделі https://doi.org/10.33480/jitk.v9i2.5015. 
 Систематизований для геномної класифікації, демонструє автоматичне усунення надлишковості 
 та забезпечення компактних піднаборів ознак https://doi.org/10.1023/A:1012487302797. 
 В дослідженні використовувалася реалізація з бібліотеки scikit-learn
 https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html.
Порівняльні дослідження демонструють конкурентну ефективність RFE відносно 
інших методів https://www.mdpi.com/2075-1729/15/4/594, 
https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00327-4, https://pmc.ncbi.nlm.nih.gov/articles/PMC6433899. 
RFE з перехресною валідацією забезпечує стійкість до перенавчання у системах 
виявлення вторгнень https://www.mdpi.com/2224-2708/12/5/67.

**Алгоритм Boruta.** Обгортковий метод для виявлення всіх релевантних ознак через порівняння з тіньовими копіями,
згенерованими випадковою пермутацією http://www.jstatsoft.org/v36/i11. 
В дослідженні використана Python-реалізація сумісна з ensemble методами 
scikit-learn https://pypi.org/project/Boruta. 
Ефективність підтверджена у медичній діагностиці https://www.mdpi.com/2075-1729/15/4/594,
 класифікації даних https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00327-4,
 https://pmc.ncbi.nlm.nih.gov/articles/PMC6433899, https://ieeexplore.ieee.org/document/9101199, 
 прогнозування діабету https://doi.org/10.1186/s12859-023-05300-5 та
 радіоміки https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0261401; 
 у фінансах для P2P кредитування https://ieeexplore.ieee.org/document/10440917, 
 кредитного скорингу https://www.mdpi.com/2079-8954/12/7/254 із забезпеченням 3-4% 
 приросту точності при скороченні часу інференсу https://ieeexplore.ieee.org/document/10711357.

Для кожного методу формується послідовність підмножин ознак, для яких тренується модель XGBoost
з оптимізованими гіперпараметрами та обчислюється значення метрики AUC-PR на тестовій вибірці.
Кожен метод тестується на послідовності наборів ознак різного розміру,
що дозволяє побудувати криві залежності якості від кількості ознак та визначити оптимальну конфігурацію
для кожної стратегії.

## РЕЗУЛЬТАТИ ТА ДИСКУСІЇ

3.1 БАЗОВЕ ТЕСТУВАННЯ ТА ОПТИМІЗАЦІЯ

Систематична оцінка ефективності різних етапів оптимізації виявила поступове покращення якості моделей
через комплексний підхід до налаштування параметрів та відбору ознак.

Базові моделі з усіма ознаками та параметрами за замовчуванням досягли AUC-PR 0.9750 для першого датасету
та 0.9745 для другого датасету, демонструючи високу інформативність вхідних даних,
ефективність процедур попередньої обробки та
значну прогностичну здатність XGBoost у базовій конфігурації.

Оптимізація гіперпараметрів за допомогою фреймворку Optuna забезпечила покращення показників
до 0.9783 для першого датасету та 0.9770 для другого датасету, що представляє покращення на 0.33% та 0.25% відповідно.

Результати оптимізації та отримані гіперпараметри для обох наборів даних наведені в таблиці:

**Порівняльна таблиця результатів оптимізації гіперпараметрів:**

|Параметр|Датасет 1|Датасет 2|
|---|---|---|
|**Початкове AUC-PR**|0.9750 |0.9745|
|**Покращення AUC-PR**|0.9783 (+0.33%)|0.9770 (+0.25%)|
|**Кількість дерев**|750|800|
|**Швидкість навчання**|0.02|0.1|
|**Максимальна глибина**|12|7|
|**Мінімальна вага дочірнього вузла**|2|3|
|**Gamma**|0.7|0.2|
|**Subsample**|0.97|1.0|
|**Colsample_bytree**|0.69|0.7|
|**Reg_alpha**|0.9|0.5|
|**Reg_lambda**|0.35|2.0|

Різниця в оптимальних параметрах свідчить про відмінності у структурі та характеристиках датасетів,
що потребує індивідуального підходу до налаштування моделей.

3.2 ПОРІВНЯЛЬНИЙ АНАЛІЗ МЕТОДІВ ВІДБОРУ ОЗНАК

Для обох датасетів побудовано криві залежності AUC-PR від кількості ознак для всіх методів 
 у діапазоні від 12 до 24 ознак (рис. 1).
 
 Зниження кількості ознак нижче 12 приводить до погіршення якості моделі не залежно від методу відбору.

[image:1]

Максимальні значення AUC-PR для кожного методу та датасету наведено у таблиці нижче:

| Метод                | Датасет 1: AUC-PR (n)      | Датасет 2: AUC-PR (n)      |
|----------------------|----------------------------|----------------------------|
| Прямий XGBoost       | 0.97841 (19)               | 0.97740 (24)               |
| Зворотній XGBoost    | 0.97849 (20)               | 0.97767 (14)               |
| Прямий Greedy        | **0.97873 (16)**               | 0.97764 (22)               |
| Зворотній Greedy     | 0.97870 (23)               | **0.97785 (16)**               |
| RFE                  | 0.97841 (19)               | 0.97752 (16)               |
| Boruta               | 0.97830 (22)               | 0.97712 (19)               |

Аналіз показує, що для обох датасетів найвищі значення AUC-PR досягаються саме жадібними методами
відбору ознак при однаковій оптимальній кількості 16 ознак, проте оптимальний тип жадібного алгоритму різниться.
Для датасету 1 максимальний результат забезпечує GFS (AUC-PR = 0.97873),
тоді як для датасету 2 найкращим є GBE (AUC-PR = 0.97785).
Це свідчить про чутливість оптимальної стратегії до особливостей вибірки, навіть за схожої структури даних.

3.3 АНАЛІЗ ІНФОРМАТИВНОСТІ ТА СТАБІЛЬНОСТІ ОЗНАК

Дослідження частоти включення ознак у найкращі набори (рис.2) виявило набір ключових характеристик,
що стабільно використовуються всіма методами на обох датасетах:

order_messages,
create_date_months,
order_amount,
order_changes,
order_lines_count,
source,
partner_success_avg_amount,
salesperson,
partner_success_avg_messages.

[image:2]

Ці дев'ять ознак демонструють максимальну частоту включення (6 з 6 методів)
та високу прогностичну цінність незалежно від специфіки конкретного датасету.

Теплова карта  (рис.3) демонструє, що більшість ключових ознак стабільно включаються у найкращі набори для
обох датасетів (зелена заливка). Проте для окремих ознак спостерігаються відмінності:
деякі ознаки обираються лише для одного з датасетів (блакитна або помаранчева заливка).

[image:3]

Аналіз частоти використання ознак показує, що більшість характеристик (17 з 24) включається у найкращі набори
принаймні чотирма з шести методів, підтверджуючи стабільність ключових ознак для прогнозування
успішності B2B замовлень.

Ознаки які показали максимальне значення цільової метрики для обох досліджених наборів даних наведені в таблиці:

| Ознака | Набір даних 1 | Набір даних 2 |
|--------|---------------|---------------|
| **Спільні ознаки для обох наборів даних** | | |
| order_messages | ✓ | ✓ |
| order_amount | ✓ | ✓ |
| order_changes | ✓ | ✓ |
| partner_success_rate | ✓ | ✓ |
| partner_success_avg_amount | ✓ | ✓ |
| partner_fail_avg_amount | ✓ | ✓ |
| partner_total_messages | ✓ | ✓ |
| partner_success_avg_messages | ✓ | ✓ |
| order_lines_count | ✓ | ✓ |
| discount_total | ✓ | ✓ |
| salesperson | ✓ | ✓ |
| source | ✓ | ✓ |
| create_date_months | ✓ | ✓ |
| hour_of_day | ✓ | ✓ |
| **Унікальні ознаки** | | |
| partner_success_avg_changes | ✓ | — |
| partner_avg_amount | ✓ | — |
| partner_total_orders | — | ✓ |
| quarter | — | ✓ |
| **Загальна кількість ознак** | **16** | **16** |
| **Значення цільової метрики** | **0.9787** | **0.9778** |

Результати порівняльного аналізу демонструють високий ступінь збіжності оптимальних ознак між досліджуваними наборами даних.
З 16 ознак в кожному наборі, 14 (87.5%) є спільними для обох конфігурацій: 
order_messages, order_amount, order_changes, partner_success_rate, partner_success_avg_amount, partner_fail_avg_amount, partner_total_messages, partner_success_avg_messages, order_lines_count, discount_total, salesperson, source, create_date_months, hour_of_day.
Це вказує на стабільність найважливіших предикторів, схожість структури бізнес-процесів та надійність методів відбору ознак.

3.4 ПОРІВНЯЛЬНИЙ АНАЛІЗ СТРАТЕГІЙ МОДЕЛЮВАННЯ

Порівняльний аналіз стратегій моделювання на обох датасетах підтвердив ефективність комплексного підходу,
проте з різними оптимальними конфігураціями.

**Датасет 1**
Базова модель з усіма ознаками досягла accuracy 0.9290, precision 0.9218, recall 0.9698, F1-міри 0.9452, ROC AUC 0.9663 та AUC-PR 0.9750. 
Оптимізація гіперпараметрів покращила показники до 0.9311, 0.9310, 0.9621, 0.9463, 0.9697 та 0.9783 відповідно.
Найкраща конфігурація (жадібний прямий відбір, 16 ознак + Optuna) досягла 0.9317, 0.9315, 0.9625, 0.9467, 0.9702
та 0.9787.

**Датасет 2**
Базова модель з усіма ознаками досягла accuracy 0.9293, precision 0.9212, recall 0.9710, F1-міри 0.9455, ROC AUC 0.9666 та AUC-PR 0.9745. 
Оптимізація гіперпараметрів покращила показники до 0.9305, 0.9227, 0.9713, 0.9464, 0.9686 та 0.9770.
Найкраща конфігурація (жадібний зворотний відбір, 16 ознак + Optuna) досягла 0.9313, 0.9229, 0.9722, 0.9469, 0.9691
та 0.9778.

Порівняльна таблиця метрик для обох датасетів:

|Стратегія|accuracy|precision|recall|F1-міра|ROC AUC|AUC-PR|
|---|---|---|---|---|---|---|
|Усі ознаки (default) (DS1)|0.9290|0.9218|0.9698|0.9452|0.9663|0.9750|
|Усі ознаки + Optuna (DS1)|0.9311|0.9310|0.9621|0.9463|0.9697|0.9783|
|Найкращі ознаки (GFS, 16) + Optuna (DS1)|0.9317|0.9315|0.9625|0.9467|0.9702|0.9787|
|Усі ознаки (default) (DS2)|0.9293|0.9212|0.9710|0.9455|0.9666|0.9745|
|Усі ознаки + Optuna (DS2)|0.9313|0.9229|0.9722|0.9469|0.9686|0.9770|
|Найкращі ознаки (GBE, 16) + Optuna (DS2)|0.9305|0.9227|0.9713|0.9464|0.9691|0.9778|

Датасет 1 виявляє вищу чутливість до оптимізації гіперпараметрів з покращенням AUC-PR на 0.33%,
тоді як Датасет 2 демонструє менший ефект від цього етапу з приростом лише 0.25%.
Водночас Датасет 2 показує більший ефект від процедури відбору ознак з покращенням на 0.08%
порівняно з меншим приростом в 0.04% для Датасету 1.

Оптимальні стратегії відбору ознак виявилися специфічними для кожного датасету:
прямий жадібний алгоритм забезпечив найкращі результати для Датасету 1,
тоді як для Датасету 2 оптимальним став зворотний жадібний підхід.
Примітно, що обидва алгоритми відбору конвергували до однакової кількості ознак (16),
що може свідчити про існування оптимального балансу між інформативністю та складністю моделі
для даної предметної області.

Загальний приріст якості виявився вищим для Датасету 1 з покращенням AUC-PR на 0.37%
порівняно з 0.33% для Датасету 2, що свідчить про різну якість та інформативність досліджуваних даних.

Матриці помилок (рис.4) показують суттєве зниження кількості помилкових оцінювань при одночасному зниженні розмірності даних на 33%.
 Для першого датасету кількість помилок зменшилася з 1848 до 1779 (покращення на 3.7%),
 для другого з 1840 до 1790 помилок (покращення на 2.7%).

[image:4]

3.5 ОБГОВОРЕННЯ РЕЗУЛЬТАТІВ

Результати дослідження підтверджують, що автоматизований відбір ознак є важливим компонентом покращення якості моделей
градієнтного бустингу для B2B прогнозування.

Це узгоджується з попередніми дослідженнями, які підкреслюють важливість відбору ознак для підвищення точності,
ефективності та інтерпретованості моделей машинного навчання: 
https://doi.org/10.1145/2623330.2623635,
https://ieeexplore.ieee.org/document/9236652, 
https://jeeemi.org/index.php/jeeemi/article/view/388,
https://doi.org/10.1145/3647750.3647754


Порівняльний аналіз результатів на двох датасетах виявив важливі закономірності та відмінності у ефективності методів відбору ознак.

Жадібні методи продемонстрували найкращу ефективність на обох датасетах,
проте з різними оптимальними стратегіями: прямий відбір для датасету 1 та зворотний для датасету 2.

Це підкреслює, що оптимальний метод відбору ознак може відрізнятися залежно від характеристик конкретного набору B2B даних:
https://www.mdpi.com/2076-3417/9/13/2764,
https://www.mdpi.com/2073-8994/12/7/1147,


Результати демонструють синергетичний ефект поєднання оптимізації гіперпараметрів та відбору ознак на обох датасетах,
проте з різною інтенсивністю.
Для датасету 1 оптимізація гіперпараметрів забезпечила покращення на 0.33% AUC-PR,
тоді як додатковий відбір ознак дав ще 0.04% покращення при зменшенні розмірності на 33%.
Датасет 2 показав менше покращення від оптимізації гіперпараметрів (+0.25%), але більший ефект від відбору ознак (+0.08%).

Це підтверджує гіпотезу про взаємозв'язок між оптимальними параметрами моделі та набором ознак
https://doi.org/10.1145/3377930.3389815,
https://doi.org/10.48550/arXiv.1802.09419,
https://doi.org/10.1145/3580305.3599322
,
та підкреслює важливість врахування специфіки конкретного датасету.

Переважна кількість найбільш впливових параметрів виявилася пов'язаними з тривалістю, якістю та інтенсивністю взаємодії з клієнтом.
Ці результати узгоджуються з бізнес-логікою B2B транзакцій, де довіра, історія співпраці та інтенсивність
комунікації є ключовими факторами успіху, що підтверджується дослідженнями у сфері B2B електронної
комерції [посилання на статтю в вісник].

Отримані результати мають важливі практичні наслідки для розробки систем прогнозування у B2B сфері.

Зменшення набору ознак на 33%,що призводить до полегшення аналізу та пояснення результатів бізнес-користувачам
https://doi.org/10.1145/3411764.3445315,
https://ieeexplore.ieee.org/document/8607010,
https://doi.org/10.1016/j.eswa.2024.124074,

,
при одночасному зниженню помилкових оцінок на 2,7-3,7 % робить запропонований підхід привабливим для практичного впровадження.

## ВИСНОВКИ

Проведене дослідження на двох незалежних датасетах демонструє значну ефективність комплексного підходу
до оптимізації моделей машинного навчання для прогнозування успішності B2B замовлень.

Жадібні методи показали себе як найбільш результативні на обох досліджуваних датасетах,
проте з відмінностями в оптимальних стратегіях.

Дослідження виявило, що оптимальна стратегія відбору ознак залежить від специфічних характеристик датасету.
Для першого датасету жадібний прямий відбір забезпечив найкращий результат (AUC-PR = 0.9787),
тоді як для другого датасету оптимальним виявився жадібний зворотний алгоритм (AUC-PR = 0.9778).
Це підкреслює важливість тестування різних підходів навіть для структурно схожих даних.

Оптимізація гіперпараметрів за допомогою Optuna забезпечила суттєве покращення якості моделей,
проте з різною ефективністю для кожного датасету. Перший датасет продемонстрував більшу чутливість
до оптимізації гіперпараметрів (покращення на 0.33%), тоді як другий датасет показав більший ефект від
процедури відбору ознак (покращення на 0.08% проти 0.04%). Загальний синергетичний ефект поєднання
відбору ознак та оптимізації гіперпараметрів забезпечив покращення на 0.37% для першого датасету та 0.33%
для другого при зменшенні розмірності на 33%.

Шістнадцять ознак виявилися оптимальним розміром набору для обох датасетів, незважаючи на різні алгоритми відбору.
Це свідчить про існування фундаментального балансу між інформативністю та складністю моделі для предметної області B2B класифікації.
Практична ефективність підтверджується зниженням кількості помилкових класифікацій:
з 1848 до 1779 помилок (3.7%) для першого датасету та з 1840 до 1790 помилок (2.7%) для другого.

Дослідження ідентифікувало дев'ять критично важливих ознак, що стабільно використовуються всіма методами на обох датасетах: 
order_messages, create_date_months, order_amount, order_changes, order_lines_count, source, partner_success_avg_amount, salesperson, partner_success_avg_messages.
Загалом 14 з 16 ознак збігаються між оптимальними наборами датасетів, що вказує на універсальність ключових характеристик бізнес-процесів.

Рекомендації для практичного впровадження включають використання жадібних методів вибору ознак з обов'язковим
порівнянням прямого та зворотного підходів для вибору найкращого за показниками цільової метрики.
Впровадження автоматизованої оптимізації гіперпараметрів у виробничі системи має бути адаптивним до специфіки конкретних датасетів. 
Особливу увагу слід приділити покращенню якості збирання та обробки дев'яти виявлених критично важливих ознак,
а також регулярній переоцінці релевантності ознак при зміні бізнес-процесів.

Обмеження дослідження включають використання обмеженої кількості датасетів з однієї предметної області,
оцінювання ефективності тільки для XGBoost алгоритму, та дослідження шести методів відбору ознак.
Виявлена залежність оптимальної стратегії від характеристик датасету може зменшити узагальнюваність результатів
для інших типів B2B даних.

Наступні дослідження повинні включати тестування на більшій кількості різноманітних датасетів з B2B платформ для
підтвердження універсальності виявлених закономірностей, порівняння з іншими алгоритмами машинного навчання, дослідження
додаткових методів відбору ознак, включаючи гібридні підходи, та розробку автоматизованих систем вибору оптимальної стратегії
на основі характеристик датасету.

Отримані результати створюють підґрунтя для розвитку більш ефективних та адаптивних систем прогнозування
у сфері B2B електронної комерції та демонструють важливість комплексного підходу до оптимізації моделей машинного
навчання з урахуванням специфіки конкретних даних.
	