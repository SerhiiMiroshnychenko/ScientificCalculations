"""
üî¨ –ê–ù–ê–õ–Ü–ó –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –û–ó–ù–ê–ö –ó –û–ü–¢–ò–ú–ê–õ–¨–ù–ò–ú–ò –ü–ê–†–ê–ú–ï–¢–†–ê–ú–ò XGBOOST

–¶–µ–π —Å–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç—É—î –º–æ–¥–µ–ª—å XGBoost –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –∑–Ω–∞–π–¥–µ–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
–Ω–∞ –≤—Å—ñ—Ö –º–æ–∂–ª–∏–≤–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è—Ö –æ–∑–Ω–∞–∫ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —ó—Ö –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ.

–ï—Ç–∞–ø–∏ —Ä–æ–±–æ—Ç–∏:
1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫
2. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∑ hyperparameter research
3. –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –æ–∑–Ω–∞–∫ (1, 2, 3, ..., n)
4. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó
5. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π —Ç–∞ —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤
6. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤–∏—Å–Ω–æ–≤–∫—ñ–≤ –ø—Ä–æ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2024
"""

import pandas as pd
import numpy as np

# –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è non-interactive backend –¥–ª—è matplotlib (–≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ Tcl/Tk)
import matplotlib
matplotlib.use('Agg')  # Backend –±–µ–∑ GUI - –≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ Tcl/Tk
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, average_precision_score
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
import itertools
import warnings
import os
import time

import pickle

warnings.filterwarnings('ignore')

class FeatureCombinationAnalyzer:
    """
    –ö–ª–∞—Å –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π —Ç–æ–ø –æ–∑–Ω–∞–∫ –∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ XGBoost
    """

    def __init__(self, data_path, random_state=42, top_features_count=5):
        self.data_path = data_path
        self.random_state = random_state
        self.top_features_count = top_features_count  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø –æ–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É

        # –û–ü–¢–ò–ú–ê–õ–¨–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –∑ hyperparameter research
        self.optimal_params = {
            'subsample': 1.0,
            'reg_lambda': 2.0,
            'reg_alpha': 0.5,
            'n_estimators': 800,
            'min_child_weight': 3,
            'max_depth': 7,
            'learning_rate': 0.1,
            'gamma': 0.2,
            'colsample_bytree': 0.7,
            'objective': 'binary:logistic',
            'eval_metric': 'aucpr',  # AUC-PR –º–µ—Ç—Ä–∏–∫–∞ –≤ XGBoost
            'random_state': random_state,
            'n_jobs': -1,
            'verbosity': 0
        }

        # –ó–º—ñ–Ω–Ω—ñ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.data = None
        self.feature_names = None
        self.top_feature_names = None  # –¢–æ–ø –æ–∑–Ω–∞–∫–∏ –∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é
        self.feature_importance_scores = None  # –û—Ü—ñ–Ω–∫–∏ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.scaler = None
        self.results = []
        self.best_combinations = {}

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.results_dir = f"feature_analysis_results"
        os.makedirs(self.results_dir, exist_ok=True)

        print(f"üî¨ === –ê–ù–ê–õ–Ü–ó –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö –ó –û–ü–¢–ò–ú–ê–õ–¨–ù–ò–ú–ò –ü–ê–†–ê–ú–ï–¢–†–ê–ú–ò ===")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤: {self.results_dir}/")
        print(f"üéØ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ hyperparameter research")
        print(f"‚ö° –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è: –∞–Ω–∞–ª—ñ–∑ —Ç—ñ–ª—å–∫–∏ —Ç–æ–ø-{self.top_features_count} –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏—Ö –æ–∑–Ω–∞–∫")
        print(f"üñºÔ∏è –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —è–∫ PNG —Ñ–∞–π–ª–∏ (non-interactive —Ä–µ–∂–∏–º)")

    def load_and_prepare_data(self):
        """
        –ï–¢–ê–ü 0: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
        """
        print(f"\nüîÑ === –ï–¢–ê–ü 0: –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–• ===")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑: {self.data_path}")
        self.data = pd.read_csv(self.data_path)
        print(f"üìä –†–æ–∑–º—ñ—Ä –¥–∞–Ω–∏—Ö: {self.data.shape}")

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
        if 'is_successful' not in self.data.columns:
            raise ValueError("‚ùå –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ 'is_successful' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!")

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫ (—Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏, —è–∫ –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ)
        exclude_columns = ['order_id', 'is_successful', 'create_date', 'partner_id']

        # –í–∫–ª—é—á–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ
        numeric_features = [
            'order_amount', 'order_messages', 'order_changes',
            'partner_success_rate', 'partner_total_orders', 'partner_order_age_days',
            'partner_avg_amount', 'partner_success_avg_amount', 'partner_fail_avg_amount',
            'partner_total_messages', 'partner_success_avg_messages', 'partner_fail_avg_messages',
            'partner_avg_changes', 'partner_success_avg_changes', 'partner_fail_avg_changes'
        ]

        # –í—ñ–¥–±–∏—Ä–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ç—ñ –æ–∑–Ω–∞–∫–∏, —â–æ —Ä–µ–∞–ª—å–Ω–æ —î –≤ –¥–∞–Ω–∏—Ö
        self.feature_names = [col for col in numeric_features if col in self.data.columns]

        print(f"üîç –ó–Ω–∞–π–¥–µ–Ω–æ –æ–∑–Ω–∞–∫: {len(self.feature_names)}")
        print(f"üìã –°–ø–∏—Å–æ–∫ –æ–∑–Ω–∞–∫: {self.feature_names}")

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ (—è–∫ –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ)
        print(f"üîß –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –æ–∑–Ω–∞–∫...")
        data_with_features = self._create_additional_features(self.data)

        # –û–Ω–æ–≤–ª—é—î–º–æ —Å–ø–∏—Å–æ–∫ –æ–∑–Ω–∞–∫ –≤–∫–ª—é—á–∞—é—á–∏ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ
        additional_features = [col for col in data_with_features.columns
                             if col.endswith('_diff') or col.endswith('_ratio')]
        all_features = self.feature_names + additional_features

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ X —Ç–∞ y
        X = data_with_features[all_features]
        y = data_with_features['is_successful']

        # –û–Ω–æ–≤–ª—é—î–º–æ —Å–ø–∏—Å–æ–∫ –æ–∑–Ω–∞–∫
        self.feature_names = all_features

        print(f"üéØ –†–æ–∑–ø–æ–¥—ñ–ª —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó:")
        print(f"  ‚Ä¢ –£—Å–ø—ñ—à–Ω—ñ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è: {y.sum()} ({y.mean():.1%})")
        print(f"  ‚Ä¢ –ù–µ—É—Å–ø—ñ—à–Ω—ñ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è: {(~y.astype(bool)).sum()} ({(1-y.mean()):.1%})")

        # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/test (70%/30%)
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.3, random_state=self.random_state, stratify=y
        )

        print(f"üìä –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö:")
        print(f"  ‚Ä¢ –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∞ –≤–∏–±—ñ—Ä–∫–∞: {self.X_train.shape[0]} –∑—Ä–∞–∑–∫—ñ–≤")
        print(f"  ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞ –≤–∏–±—ñ—Ä–∫–∞: {self.X_test.shape[0]} –∑—Ä–∞–∑–∫—ñ–≤")

        # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫
        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        print(f"‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É")

    def select_top_features(self):
        """
        –ï–¢–ê–ü 0.5: –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–æ–ø –æ–∑–Ω–∞–∫ –∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é XGBoost
        """
        print(f"\nüîÑ === –ï–¢–ê–ü 0.5: –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö ===")

        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –Ω–∞ –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫–∞—Ö –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è feature importance
        print(f"ü§ñ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è XGBoost –Ω–∞ –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫–∞—Ö –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ...")
        importance_model = XGBClassifier(**self.optimal_params)
        importance_model.fit(self.X_train_scaled, self.y_train)

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫
        feature_importance = importance_model.feature_importances_

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –¥–ª—è —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)

        print(f"üìä –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å —É—Å—ñ—Ö –æ–∑–Ω–∞–∫:")
        for i, (_, row) in enumerate(importance_df.iterrows(), 1):
            print(f"  {i:2d}. {row['feature']:<35} {row['importance']:.6f}")

        # –í–∏–±—ñ—Ä —Ç–æ–ø –æ–∑–Ω–∞–∫
        self.top_feature_names = importance_df.head(self.top_features_count)['feature'].tolist()
        self.feature_importance_scores = importance_df.head(self.top_features_count)

        print(f"\nüèÜ –í–∏–±—Ä–∞–Ω—ñ —Ç–æ–ø-{self.top_features_count} –æ–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:")
        for i, feature in enumerate(self.top_feature_names, 1):
            importance_score = importance_df[importance_df['feature'] == feature]['importance'].iloc[0]
            print(f"  {i}. {feature} (–≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å: {importance_score:.6f})")

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—ñ–≤ —Ç–æ–ø –æ–∑–Ω–∞–∫
        self.top_feature_indices = [self.feature_names.index(feature) for feature in self.top_feature_names]

        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–æ–±–æ—Ç–∏ —Ç—ñ–ª—å–∫–∏ –∑ —Ç–æ–ø –æ–∑–Ω–∞–∫–∞–º–∏
        self.X_train_top = self.X_train_scaled[:, self.top_feature_indices]
        self.X_test_top = self.X_test_scaled[:, self.top_feature_indices]

        print(f"‚úÖ –î–∞–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω—ñ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Ç–æ–ø-{self.top_features_count} –æ–∑–Ω–∞–∫–∞–º–∏")

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫
        importance_df.to_csv(f'{self.results_dir}/feature_importance_all.csv', index=False)
        self.feature_importance_scores.to_csv(f'{self.results_dir}/top_features_selected.csv', index=False)

        return importance_df

    def _create_additional_features(self, df):
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ (—Ç–æ—á–Ω–æ —è–∫ –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ)"""
        df = df.copy()

        # –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ —Å–µ—Ä–µ–¥–Ω—ñ–º–∏ —Å—É–º–∞–º–∏ —É—Å–ø—ñ—à–Ω–∏—Ö —Ç–∞ –Ω–µ—É—Å–ø—ñ—à–Ω–∏—Ö –∑–∞–º–æ–≤–ª–µ–Ω—å
        if ('partner_success_avg_amount' in df.columns and
            'partner_fail_avg_amount' in df.columns):
            df['amount_success_fail_diff'] = (df['partner_success_avg_amount'] -
                                            df['partner_fail_avg_amount'])

        # –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ —Å–µ—Ä–µ–¥–Ω—å–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å —É—Å–ø—ñ—à–Ω–∏—Ö —Ç–∞ –Ω–µ—É—Å–ø—ñ—à–Ω–∏—Ö –∑–∞–º–æ–≤–ª–µ–Ω—å
        if ('partner_success_avg_messages' in df.columns and
            'partner_fail_avg_messages' in df.columns):
            df['messages_success_fail_diff'] = (df['partner_success_avg_messages'] -
                                              df['partner_fail_avg_messages'])

        # –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ —Å–µ—Ä–µ–¥–Ω—å–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –∑–º—ñ–Ω —É—Å–ø—ñ—à–Ω–∏—Ö —Ç–∞ –Ω–µ—É—Å–ø—ñ—à–Ω–∏—Ö –∑–∞–º–æ–≤–ª–µ–Ω—å
        if ('partner_success_avg_changes' in df.columns and
            'partner_fail_avg_changes' in df.columns):
            df['changes_success_fail_diff'] = (df['partner_success_avg_changes'] -
                                             df['partner_fail_avg_changes'])

        # –í—ñ–¥–Ω–æ—à–µ–Ω–Ω—è —Å—É–º–∏ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è –¥–æ —Å–µ—Ä–µ–¥–Ω—å–æ—ó —Å—É–º–∏ –∑–∞–º–æ–≤–ª–µ–Ω—å –ø–∞—Ä—Ç–Ω–µ—Ä–∞
        if ('order_amount' in df.columns and
            'partner_avg_amount' in df.columns):
            df['order_amount_to_avg_ratio'] = df['order_amount'] / df['partner_avg_amount']

        # –ó–∞–º—ñ–Ω–∞ –Ω–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å —Ç–∞ NaN –Ω–∞ 0
        df = df.replace([np.inf, -np.inf], np.nan)
        df = df.fillna(0)

        additional_features = [col for col in df.columns if col.endswith('_diff') or col.endswith('_ratio')]
        if additional_features:
            print(f"  ‚úÖ –°—Ç–≤–æ—Ä–µ–Ω—ñ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –æ–∑–Ω–∞–∫–∏: {additional_features}")

        return df

    def test_feature_combination(self, feature_indices, combination_size):
        """
        –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Ç–æ–ø –æ–∑–Ω–∞–∫
        """
        # –í–∏–±—ñ—Ä –æ–∑–Ω–∞–∫ –∑ —Ç–æ–ø –æ–∑–Ω–∞–∫ (—ñ–Ω–¥–µ–∫—Å–∏ –≤—ñ–¥–Ω–æ—Å–Ω–æ —Ç–æ–ø –æ–∑–Ω–∞–∫)
        X_train_combo = self.X_train_top[:, feature_indices]
        X_test_combo = self.X_test_top[:, feature_indices]

        feature_combo_names = [self.top_feature_names[i] for i in feature_indices]

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        model = XGBClassifier(**self.optimal_params)

        # Cross-validation –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ (5-fold)
        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)

        cv_f1_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='f1')
        cv_auc_roc_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='roc_auc')
        cv_auc_pr_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='average_precision')

        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        model.fit(X_train_combo, self.y_train)

        # –ü—Ä–æ–≥–Ω–æ–∑–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ
        y_pred = model.predict(X_test_combo)
        y_pred_proba = model.predict_proba(X_test_combo)[:, 1]

        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫
        metrics = {
            'combination_size': combination_size,
            'feature_indices': feature_indices,
            'feature_names': feature_combo_names,
            'feature_names_str': ' + '.join(feature_combo_names),

            # CV –º–µ—Ç—Ä–∏–∫–∏
            'cv_f1_mean': cv_f1_scores.mean(),
            'cv_f1_std': cv_f1_scores.std(),
            'cv_auc_roc_mean': cv_auc_roc_scores.mean(),
            'cv_auc_roc_std': cv_auc_roc_scores.std(),
            'cv_auc_pr_mean': cv_auc_pr_scores.mean(),
            'cv_auc_pr_std': cv_auc_pr_scores.std(),

            # Test –º–µ—Ç—Ä–∏–∫–∏
            'test_f1': f1_score(self.y_test, y_pred),
            'test_accuracy': accuracy_score(self.y_test, y_pred),
            'test_precision': precision_score(self.y_test, y_pred),
            'test_recall': recall_score(self.y_test, y_pred),
            'test_auc_roc': roc_auc_score(self.y_test, y_pred_proba),
            'test_auc_pr': average_precision_score(self.y_test, y_pred_proba),

            # –†—ñ–∑–Ω–∏—Ü—è CV vs Test (–æ–∑–Ω–∞–∫–∞ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è)
            'overfitting_gap_f1': cv_f1_scores.mean() - f1_score(self.y_test, y_pred),
            'overfitting_gap_auc_pr': cv_auc_pr_scores.mean() - average_precision_score(self.y_test, y_pred_proba)
        }

        return metrics

    def analyze_all_combinations(self):
        """
        –ï–¢–ê–ü 1: –ê–Ω–∞–ª—ñ–∑ –≤—Å—ñ—Ö –º–æ–∂–ª–∏–≤–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π —Ç–æ–ø –æ–∑–Ω–∞–∫
        """
        print(f"\nüîÑ === –ï–¢–ê–ü 1: –ê–ù–ê–õ–Ü–ó –í–°–Ü–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö ===")

        n_features = self.top_features_count  # –ü—Ä–∞—Ü—é—î–º–æ —Ç—ñ–ª—å–∫–∏ –∑ —Ç–æ–ø –æ–∑–Ω–∞–∫–∞–º–∏
        total_combinations = 2**n_features - 1  # –í—Å—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó –∫—Ä—ñ–º –ø—É—Å—Ç–æ—ó

        print(f"üî¢ –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {total_combinations}")
        print(f"‚ö° –¢–æ–ø –æ–∑–Ω–∞–∫–∏: {', '.join(self.top_feature_names)}")

        max_combination_size = n_features  # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤—Å—ñ –º–æ–∂–ª–∏–≤—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Ç–æ–ø –æ–∑–Ω–∞–∫

        start_time = time.time()
        processed = 0

        # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –≤—ñ–¥ 1 –¥–æ max_combination_size –æ–∑–Ω–∞–∫
        for combination_size in range(1, max_combination_size + 1):
            print(f"\nüìä –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –∑ {combination_size} –æ–∑–Ω–∞–∫...")

            combinations = list(itertools.combinations(range(n_features), combination_size))
            n_combinations = len(combinations)

            print(f"üî¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {n_combinations}")

            for i, feature_indices in enumerate(combinations):
                if i % max(1, n_combinations // 10) == 0:
                    progress = (i / n_combinations) * 100
                    print(f"  üìà –ü—Ä–æ–≥—Ä–µ—Å: {progress:.1f}% ({i}/{n_combinations})")

                try:
                    metrics = self.test_feature_combination(feature_indices, combination_size)
                    self.results.append(metrics)
                    processed += 1

                except Exception as e:
                    print(f"  ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–ª—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó {feature_indices}: {e}")
                    continue

        total_time = time.time() - start_time
        print(f"\n‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –û–±—Ä–æ–±–ª–µ–Ω–æ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {processed}")

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        self.results_df = pd.DataFrame(self.results)

        # –ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É (–∑–∞ AUC-PR)
        for size in range(1, max_combination_size + 1):
            size_results = self.results_df[self.results_df['combination_size'] == size]
            if not size_results.empty:
                best_idx = size_results['test_auc_pr'].idxmax()  # –û–ø—Ç–∏–º—ñ–∑—É—î–º–æ –∑–∞ AUC-PR
                self.best_combinations[size] = self.results_df.loc[best_idx]

        print(f"üèÜ –ù–∞–π–∫—Ä–∞—â—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó –∑–Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É")

    def create_visualizations(self):
        """
        –ï–¢–ê–ü 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
        """
        print(f"\nüîÑ === –ï–¢–ê–ü 2: –°–¢–í–û–†–ï–ù–ù–Ø –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–ô ===")
        print(f"üñºÔ∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ matplotlib backend 'Agg' (non-interactive)")

        try:
            # 1. –†–æ–∑–ø–æ–¥—ñ–ª –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π
            print(f"  üìä –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö...")
            self._plot_metrics_by_size()

            # 2. –¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π
            print(f"  üèÜ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ —Ç–æ–ø –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π...")
            self._plot_top_combinations()

            # 3. –ê–Ω–∞–ª—ñ–∑ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫
            print(f"  üéØ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫...")
            self._plot_individual_features()

            # 4. Heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏
            print(f"  üî• –°—Ç–≤–æ—Ä–µ–Ω–Ω—è heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ—ó...")
            self._plot_metrics_correlation()

            # 5. –ê–Ω–∞–ª—ñ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
            print(f"  üìà –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è...")
            self._plot_overfitting_analysis()

            print(f"‚úÖ –í—Å—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ!")

        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π: {e}")
            print(f"‚ö†Ô∏è –ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ –±–µ–∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π...")
            return False

        return True

    def _plot_metrics_by_size(self):
        """–ì—Ä–∞—Ñ—ñ–∫ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('–ê–Ω–∞–ª—ñ–∑ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –æ–∑–Ω–∞–∫', fontsize=16, fontweight='bold')

        metrics = ['test_f1', 'test_auc_pr', 'test_auc_roc', 'overfitting_gap_auc_pr']
        titles = ['F1 Score', 'AUC-PR (Primary)', 'AUC-ROC', 'Overfitting Gap AUC-PR (CV - Test)']

        for i, (metric, title) in enumerate(zip(metrics, titles)):
            ax = axes[i//2, i%2]

            # Box plot –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É
            sizes = sorted(self.results_df['combination_size'].unique())
            data_by_size = [self.results_df[self.results_df['combination_size'] == size][metric]
                           for size in sizes]

            bp = ax.boxplot(data_by_size, labels=sizes, patch_artist=True)

            # –ö–æ–ª—å–æ—Ä–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è
            colors = plt.cm.viridis(np.linspace(0, 1, len(sizes)))
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)

            ax.set_title(title, fontweight='bold')
            ax.set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ –≤ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó')
            ax.set_ylabel(title)
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/metrics_by_combination_size.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_top_combinations(self):
        """–¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π"""
        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –ø–æ test_auc_pr (–æ—Å–Ω–æ–≤–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞)
        top_combinations = self.results_df.nlargest(10, 'test_auc_pr')

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))

        # –ì—Ä–∞—Ñ—ñ–∫ 1: AUC-PR Score —Ç–æ–ø-10
        bars1 = ax1.barh(range(len(top_combinations)), top_combinations['test_auc_pr'],
                        color=plt.cm.viridis(np.linspace(0, 1, len(top_combinations))))

        ax1.set_yticks(range(len(top_combinations)))
        ax1.set_yticklabels([f"{row['combination_size']} –æ–∑–Ω–∞–∫:\n{row['feature_names_str'][:50]}..."
                            if len(row['feature_names_str']) > 50
                            else f"{row['combination_size']} –æ–∑–Ω–∞–∫:\n{row['feature_names_str']}"
                            for _, row in top_combinations.iterrows()], fontsize=10)
        ax1.set_xlabel('Test AUC-PR Score')
        ax1.set_title('–¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –æ–∑–Ω–∞–∫ (AUC-PR)', fontweight='bold')
        ax1.grid(True, alpha=0.3)

        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ bars
        for i, bar in enumerate(bars1):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2,
                    f'{width:.4f}', ha='left', va='center', fontweight='bold')

        # –ì—Ä–∞—Ñ—ñ–∫ 2: –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è CV vs Test AUC-PR –¥–ª—è —Ç–æ–ø-10
        x_pos = np.arange(len(top_combinations))
        width = 0.35

        bars1 = ax2.bar(x_pos - width/2, top_combinations['cv_auc_pr_mean'], width,
                       label='CV AUC-PR Score', alpha=0.8, color='lightblue')
        bars2 = ax2.bar(x_pos + width/2, top_combinations['test_auc_pr'], width,
                       label='Test AUC-PR Score', alpha=0.8, color='lightcoral')

        ax2.set_xlabel('–ö–æ–º–±—ñ–Ω–∞—Ü—ñ—è –æ–∑–Ω–∞–∫')
        ax2.set_ylabel('AUC-PR Score')
        ax2.set_title('CV vs Test AUC-PR Score –¥–ª—è —Ç–æ–ø-10 –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π', fontweight='bold')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels([f"{i+1}" for i in range(len(top_combinations))])
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/top_combinations.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_individual_features(self):
        """–ê–Ω–∞–ª—ñ–∑ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫"""
        # –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–∏—Ö –æ–∑–Ω–∞–∫
        single_features = self.results_df[self.results_df['combination_size'] == 1].copy()
        single_features = single_features.sort_values('test_auc_pr', ascending=True)  # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ AUC-PR

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))

        # –ì—Ä–∞—Ñ—ñ–∫ 1: –†–µ–π—Ç–∏–Ω–≥ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫ –∑–∞ AUC-PR
        bars = ax1.barh(range(len(single_features)), single_features['test_auc_pr'],
                       color=plt.cm.RdYlGn(np.linspace(0.3, 1, len(single_features))))

        ax1.set_yticks(range(len(single_features)))
        ax1.set_yticklabels(single_features['feature_names_str'], fontsize=12)
        ax1.set_xlabel('Test AUC-PR Score')
        ax1.set_title('–†–µ–π—Ç–∏–Ω–≥ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫ (AUC-PR)', fontweight='bold', fontsize=14)
        ax1.grid(True, alpha=0.3)

        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2,
                    f'{width:.4f}', ha='left', va='center', fontweight='bold')

        # –ì—Ä–∞—Ñ—ñ–∫ 2: –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–∏ –æ–∑–Ω–∞–∫ –≤ —Ç–æ–ø-20 –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è—Ö
        top_20 = self.results_df.nlargest(20, 'test_auc_pr')  # –ó–∞ AUC-PR
        feature_counts = {}

        for _, row in top_20.iterrows():
            for feature in row['feature_names']:
                feature_counts[feature] = feature_counts.get(feature, 0) + 1

        features_sorted = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)
        features, counts = zip(*features_sorted)

        bars2 = ax2.bar(range(len(features)), counts,
                       color=plt.cm.plasma(np.linspace(0, 1, len(features))))

        ax2.set_xticks(range(len(features)))
        ax2.set_xticklabels(features, rotation=45, ha='right')
        ax2.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–∏ –≤ —Ç–æ–ø-20')
        ax2.set_title('–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–∏ –æ–∑–Ω–∞–∫ –≤ –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è—Ö', fontweight='bold', fontsize=14)
        ax2.grid(True, alpha=0.3)

        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{int(height)}', ha='center', va='bottom', fontweight='bold')

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/individual_features_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_metrics_correlation(self):
        """Heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        metrics_cols = ['test_f1', 'test_auc_pr', 'test_auc_roc', 'test_accuracy',
                       'test_precision', 'test_recall', 'cv_auc_pr_mean', 'overfitting_gap_auc_pr']

        correlation_matrix = self.results_df[metrics_cols].corr()

        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": .8}, fmt='.3f')

        plt.title('–ö–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —è–∫–æ—Å—Ç—ñ', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/metrics_correlation.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_overfitting_analysis(self):
        """–ê–Ω–∞–ª—ñ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # –ì—Ä–∞—Ñ—ñ–∫ 1: Scatter plot CV vs Test AUC-PR
        scatter = ax1.scatter(self.results_df['cv_auc_pr_mean'], self.results_df['test_auc_pr'],
                            c=self.results_df['combination_size'], cmap='viridis', alpha=0.6)

        # –õ—ñ–Ω—ñ—è —ñ–¥–µ–∞–ª—å–Ω–æ–≥–æ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        min_val = min(self.results_df['cv_auc_pr_mean'].min(), self.results_df['test_auc_pr'].min())
        max_val = max(self.results_df['cv_auc_pr_mean'].max(), self.results_df['test_auc_pr'].max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)

        ax1.set_xlabel('CV AUC-PR Score')
        ax1.set_ylabel('Test AUC-PR Score')
        ax1.set_title('CV vs Test AUC-PR Score', fontweight='bold')
        ax1.grid(True, alpha=0.3)

        # Colorbar
        cbar = plt.colorbar(scatter, ax=ax1)
        cbar.set_label('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫')

        # –ì—Ä–∞—Ñ—ñ–∫ 2: –†–æ–∑–ø–æ–¥—ñ–ª overfitting gap –¥–ª—è AUC-PR
        ax2.hist(self.results_df['overfitting_gap_auc_pr'], bins=30, alpha=0.7, color='orange', edgecolor='black')
        ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='–ù–µ–º–∞—î –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è')
        ax2.axvline(self.results_df['overfitting_gap_auc_pr'].mean(), color='blue', linestyle='-',
                   linewidth=2, label=f'–°–µ—Ä–µ–¥–Ω—î: {self.results_df["overfitting_gap_auc_pr"].mean():.4f}')

        ax2.set_xlabel('Overfitting Gap AUC-PR (CV - Test)')
        ax2.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        ax2.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è (AUC-PR)', fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/overfitting_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def generate_report(self):
        """
        –ï–¢–ê–ü 3: –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É
        """
        print(f"\nüîÑ === –ï–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ó–í–Ü–¢–£ ===")

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É CSV
        self.results_df.to_csv(f'{self.results_dir}/all_combinations_results.csv', index=False)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–æ–ø-–∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π (–∑–∞ AUC-PR)
        top_10 = self.results_df.nlargest(10, 'test_auc_pr')
        top_10.to_csv(f'{self.results_dir}/top_10_combinations.csv', index=False)

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è markdown –∑–≤—ñ—Ç—É
        report_path = f'{self.results_dir}/analysis_report.md'

        with open(report_path, 'w', encoding='utf-8') as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∑–≤—ñ—Ç—É
            f.write("# üî¨ –ó–í–Ü–¢ –ê–ù–ê–õ–Ü–ó–£ –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –û–ó–ù–ê–ö\n\n")

            # –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
            f.write("## üìä –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è\n")
            f.write(f"- –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ —É –¥–∞—Ç–∞—Å–µ—Ç—ñ: {len(self.feature_names)}\n")
            f.write(f"- –¢–æ–ø –æ–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É: {self.top_features_count}\n")
            f.write(f"- –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {len(self.results_df)}\n")
            f.write(f"- –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ XGBoost\n")
            f.write(f"- –û—Å–Ω–æ–≤–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó: AUC-PR (Area Under Precision-Recall Curve)\n\n")

            # –¢–æ–ø –æ–∑–Ω–∞–∫–∏
            f.write("## üèÜ –í–∏–±—Ä–∞–Ω—ñ —Ç–æ–ø –æ–∑–Ω–∞–∫–∏ (–∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é XGBoost)\n")
            for i, (_, row) in enumerate(self.feature_importance_scores.iterrows(), 1):
                f.write(f"{i}. **{row['feature']}** - –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å: {row['importance']:.6f}\n")
            f.write("\n")

            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            f.write("## üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ XGBoost\n")
            for param, value in self.optimal_params.items():
                f.write(f"- {param}: {value}\n")
            f.write("\n")

            # –¢–æ–ø-5 –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π
            f.write("## üèÜ –¢–û–ü-5 –ù–ê–ô–ö–†–ê–©–ò–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô (–∑–∞ AUC-PR)\n\n")
            top_5 = self.results_df.nlargest(5, 'test_auc_pr')
            for i, (_, row) in enumerate(top_5.iterrows(), 1):
                f.write(f"### {i}. –ö–æ–º–±—ñ–Ω–∞—Ü—ñ—è –∑ {row['combination_size']} –æ–∑–Ω–∞–∫\n")
                f.write(f"- **–û–∑–Ω–∞–∫–∏**: {row['feature_names_str']}\n")
                f.write(f"- **Test AUC-PR**: {row['test_auc_pr']:.6f} (Primary)\n")
                f.write(f"- **Test F1 Score**: {row['test_f1']:.6f}\n")
                f.write(f"- **Test AUC-ROC**: {row['test_auc_roc']:.6f}\n")
                f.write(f"- **Test Accuracy**: {row['test_accuracy']:.6f}\n")
                f.write(f"- **CV AUC-PR**: {row['cv_auc_pr_mean']:.6f} ¬± {row['cv_auc_pr_std']:.6f}\n")
                f.write(f"- **Overfitting Gap (AUC-PR)**: {row['overfitting_gap_auc_pr']:.6f}\n\n")

            # –ù–∞–π–∫—Ä–∞—â—ñ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏
            single_features = self.results_df[self.results_df['combination_size'] == 1].nlargest(5, 'test_auc_pr')
            f.write("## ü•á –¢–û–ü-5 –Ü–ù–î–ò–í–Ü–î–£–ê–õ–¨–ù–ò–• –û–ó–ù–ê–ö (–∑–∞ AUC-PR)\n\n")

            for i, (_, row) in enumerate(single_features.iterrows(), 1):
                f.write(f"### {i}. {row['feature_names_str']}\n")
                f.write(f"- **Test AUC-PR**: {row['test_auc_pr']:.6f} (Primary)\n")
                f.write(f"- **Test F1 Score**: {row['test_f1']:.6f}\n")
                f.write(f"- **Test AUC-ROC**: {row['test_auc_roc']:.6f}\n")
                f.write(f"- **Test Accuracy**: {row['test_accuracy']:.6f}\n\n")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π
            f.write("## üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–û–ó–ú–Ü–†–ê–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô\n\n")
            f.write("| –†–æ–∑–º—ñ—Ä | –ö—ñ–ª—å–∫—ñ—Å—Ç—å | –°–µ—Ä–µ–¥–Ω—ñ–π AUC-PR | –ù–∞–π–∫—Ä–∞—â–∏–π AUC-PR | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è |\n")
            f.write("|--------|-----------|-----------------|------------------|-----------------------|\n")

            for size in sorted(self.results_df['combination_size'].unique()):
                size_data = self.results_df[self.results_df['combination_size'] == size]
                f.write(f"| {size} | {len(size_data)} | {size_data['test_auc_pr'].mean():.6f} | {size_data['test_auc_pr'].max():.6f} | {size_data['test_auc_pr'].std():.6f} |\n")

            # –í–∏—Å–Ω–æ–≤–∫–∏
            best_overall = self.results_df.loc[self.results_df['test_auc_pr'].idxmax()]
            best_single = single_features.iloc[0]

            f.write("\n## üéØ –ö–õ–Æ–ß–û–í–Ü –í–ò–°–ù–û–í–ö–ò\n\n")

            f.write("### 1. –ù–∞–π–∫—Ä–∞—â–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è\n")
            f.write(f"- **{best_overall['combination_size']} –æ–∑–Ω–∞–∫**: {best_overall['feature_names_str']}\n")
            f.write(f"- **AUC-PR**: {best_overall['test_auc_pr']:.6f} (Primary)\n")
            f.write(f"- **F1 Score**: {best_overall['test_f1']:.6f}\n")
            improvement = ((best_overall['test_auc_pr'] / best_single['test_auc_pr'] - 1) * 100)
            f.write(f"- –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤—ñ–¥–Ω–æ—Å–Ω–æ –Ω–∞–π–∫—Ä–∞—â–æ—ó —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–æ—ó –æ–∑–Ω–∞–∫–∏: {improvement:.2f}%\n\n")

            f.write("### 2. –ù–∞–π–∫—Ä–∞—â–∞ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∞ –æ–∑–Ω–∞–∫–∞\n")
            f.write(f"- **{best_single['feature_names_str']}**\n")
            f.write(f"- **AUC-PR**: {best_single['test_auc_pr']:.6f} (Primary)\n")
            f.write(f"- **F1 Score**: {best_single['test_f1']:.6f}\n\n")

            f.write("### 3. –ê–Ω–∞–ª—ñ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è\n")
            f.write(f"- –°–µ—Ä–µ–¥–Ω—ñ–π overfitting gap (AUC-PR): {self.results_df['overfitting_gap_auc_pr'].mean():.6f}\n")
            no_overfitting = (self.results_df['overfitting_gap_auc_pr'] <= 0).sum()
            f.write(f"- –ö–æ–º–±—ñ–Ω–∞—Ü—ñ–π –±–µ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è: {no_overfitting} –∑ {len(self.results_df)}\n\n")

            f.write("### 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó\n")
            if best_overall['combination_size'] == 1:
                f.write("- –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ª–∏—à–µ –æ–¥–Ω—É –æ–∑–Ω–∞–∫—É - —Ü–µ —Å–≤—ñ–¥—á–∏—Ç—å –ø—Ä–æ –≤–∏—Å–æ–∫—É —è–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö\n")
            else:
                f.write(f"- –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {best_overall['combination_size']}\n")
                f.write("- –ö–æ–º–±—ñ–Ω—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ –¥–∞—î –∑–Ω–∞—á–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n")

            if self.results_df['overfitting_gap_auc_pr'].mean() > 0.02:
                f.write("- –ú–æ–¥–µ–ª—å —Å—Ö–∏–ª—å–Ω–∞ –¥–æ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è - –≤–∞—Ä—Ç–æ –∑–±—ñ–ª—å—à–∏—Ç–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—é\n")
            else:
                f.write("- –ú–æ–¥–µ–ª—å –¥–æ–±—Ä–µ –≥–µ–Ω–µ—Ä–∞–ª—ñ–∑—É—î - –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—ñ–¥—ñ–±—Ä–∞–Ω—ñ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ\n")

            f.write("\n## üìÅ –°—Ç–≤–æ—Ä–µ–Ω—ñ —Ñ–∞–π–ª–∏\n")
            f.write("- `all_combinations_results.csv` - –ü–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—Å—ñ—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π\n")
            f.write("- `top_10_combinations.csv` - –¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π (–∑–∞ AUC-PR)\n")
            f.write("- `feature_importance_all.csv` - –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫\n")
            f.write("- `top_features_selected.csv` - –í–∏–±—Ä–∞–Ω—ñ —Ç–æ–ø –æ–∑–Ω–∞–∫–∏\n")
            f.write("- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —É —Ñ–æ—Ä–º–∞—Ç—ñ PNG\n")

        print(f"üìÑ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_path}")
        print(f"üíæ CSV —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –ø–∞–ø—Ü—ñ: {self.results_dir}/")

    def run_analysis(self):
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
        """
        print(f"üöÄ === –ü–û–ß–ê–¢–û–ö –ê–ù–ê–õ–Ü–ó–£ –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –û–ó–ù–ê–ö ===")
        start_time = time.time()

        try:
            # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –≤—Å—ñ—Ö –µ—Ç–∞–ø—ñ–≤
            self.load_and_prepare_data()
            self.select_top_features()  # –ù–æ–≤–∏–π –µ—Ç–∞–ø: –≤–∏–±—ñ—Ä —Ç–æ–ø –æ–∑–Ω–∞–∫
            self.analyze_all_combinations()

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π (–∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫)
            visualization_success = self.create_visualizations()
            if not visualization_success:
                print(f"‚ö†Ô∏è –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω—ñ —á–µ—Ä–µ–∑ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏")
                print(f"üìä –ê–ª–µ –≤—Å—ñ –¥–∞–Ω—ñ —Ç–∞ –∑–≤—ñ—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ!")

            self.generate_report()

            total_time = time.time() - start_time

            print(f"\n‚úÖ === –ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–Ü–®–ù–û ===")
            print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–æ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {len(self.results_df)}")
            print(f"üèÜ –ù–∞–π–∫—Ä–∞—â–∏–π AUC-PR Score: {self.results_df['test_auc_pr'].max():.6f}")
            print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {self.results_dir}/")

            # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ç–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            print(f"\nü•á –¢–û–ü-3 –ù–ê–ô–ö–†–ê–©–ò–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô (–∑–∞ AUC-PR):")
            top_3 = self.results_df.nlargest(3, 'test_auc_pr')
            for i, (_, row) in enumerate(top_3.iterrows(), 1):
                print(f"{i}. {row['feature_names_str']} (AUC-PR: {row['test_auc_pr']:.6f})")

        except Exception as e:
            print(f"‚ùå –ü–û–ú–ò–õ–ö–ê: {e}")
            raise


# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
if __name__ == "__main__":
    # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∑ –¥–∞–Ω–∏–º–∏
    data_path = "b2b.csv"

    # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø –æ–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (–º–æ–∂–Ω–∞ –∑–º—ñ–Ω—é–≤–∞—Ç–∏)
    TOP_FEATURES_COUNT = 10
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞
    analyzer = FeatureCombinationAnalyzer(
        data_path=data_path, 
        random_state=42,
        top_features_count=TOP_FEATURES_COUNT
    )
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É
    analyzer.run_analysis() 