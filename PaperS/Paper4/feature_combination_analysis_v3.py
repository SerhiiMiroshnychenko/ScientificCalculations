# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, average_precision_score
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
import itertools
import warnings
import os
import time
import pickle

warnings.filterwarnings('ignore')

# === –î–û–î–ê–ù–û: –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ü–∏–∫–ª—ñ—á–Ω–∏—Ö –æ–∑–Ω–∞–∫ (—è–∫ —É analyse.py) ===
def identify_cyclical_features(feature_names):
    cyclical_pairs = {}
    sin_features = [f for f in feature_names if f.endswith('_sin')]
    for sin_feature in sin_features:
        base_name = sin_feature[:-4]
        cos_feature = f"{base_name}_cos"
        if cos_feature in feature_names:
            cyclical_pairs[base_name] = [sin_feature, cos_feature]
    return cyclical_pairs

def preprocess_features_for_analysis(X):
    feature_names = X.columns
    cyclical_pairs = identify_cyclical_features(feature_names)
    X_processed = pd.DataFrame()
    for feature in feature_names:
        is_part_of_pair = False
        for pair in cyclical_pairs.values():
            if feature in pair:
                is_part_of_pair = True
                break
        if not is_part_of_pair:
            X_processed[feature] = X[feature]
    for base_name, pair in cyclical_pairs.items():
        sin_feature, cos_feature = pair
        X_processed[base_name] = np.sqrt(X[sin_feature]**2 + X[cos_feature]**2)
    return X_processed

class FeatureCombinationAnalyzer:
    def __init__(self, data_path, random_state=42, top_features_count=5):
        self.data_path = data_path
        self.random_state = random_state
        self.top_features_count = top_features_count
        self.optimal_params = {
            'subsample': 1.0,
            'reg_lambda': 2.0,
            'reg_alpha': 0.5,
            'n_estimators': 800,
            'min_child_weight': 3,
            'max_depth': 7,
            'learning_rate': 0.1,
            'gamma': 0.2,
            'colsample_bytree': 0.7,
            'objective': 'binary:logistic',
            'eval_metric': 'aucpr',
            'random_state': random_state,
            'n_jobs': -1,
            'verbosity': 0,
            'tree_method': 'gpu_hist',
            'predictor': 'gpu_predictor',
        }
        self.data = None
        self.feature_names = None
        self.top_feature_names = None
        self.feature_importance_scores = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.scaler = None
        self.results = []
        self.best_combinations = {}
        self.extended_results = []  # –î–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π
        self.results_dir = f"feature_analysis_results_v2"
        os.makedirs(self.results_dir, exist_ok=True)
        print(f"üî¨ === –ê–ù–ê–õ–Ü–ó –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö –ó –û–ü–¢–ò–ú–ê–õ–¨–ù–ò–ú–ò –ü–ê–†–ê–ú–ï–¢–†–ê–ú–ò ===")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤: {self.results_dir}/")
        print(f"üéØ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ hyperparameter research")
        print(f"‚ö° –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è: –∞–Ω–∞–ª—ñ–∑ —Ç—ñ–ª—å–∫–∏ —Ç–æ–ø-{self.top_features_count} –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏—Ö –æ–∑–Ω–∞–∫")
        print(f"üñºÔ∏è –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —è–∫ PNG —Ñ–∞–π–ª–∏ (non-interactive —Ä–µ–∂–∏–º)")

    def load_and_prepare_data(self):
        print(f"\nüîÑ === –ï–¢–ê–ü 0: –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–• ===")
        print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑: {self.data_path}")
        self.data = pd.read_csv(self.data_path)
        print(f"üìä –†–æ–∑–º—ñ—Ä –¥–∞–Ω–∏—Ö: {self.data.shape}")
        if 'is_successful' not in self.data.columns:
            raise ValueError("‚ùå –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ 'is_successful' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!")
        # –í—ñ–¥–æ–∫—Ä–µ–º–ª—é—î–º–æ —Ü—ñ–ª—å–æ–≤—É –∑–º—ñ–Ω–Ω—É
        X = self.data.drop('is_successful', axis=1)
        y = self.data['is_successful']
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–∏—à–µ —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏
        X = X.select_dtypes(exclude=['object'])
        # === –î–û–î–ê–ù–û: –û–±'—î–¥–Ω–∞–Ω–Ω—è —Ü–∏–∫–ª—ñ—á–Ω–∏—Ö –æ–∑–Ω–∞–∫ ===
        X_processed = preprocess_features_for_analysis(X)
        self.feature_names = list(X_processed.columns)
        print(f"üîç –ó–∞–ª–∏—à–∏–ª–æ—Å—å —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ —Ü–∏–∫–ª—ñ—á–Ω–∏—Ö: {len(self.feature_names)}")
        # –î—ñ–ª–∏–º–æ –Ω–∞ train/test
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X_processed, y, test_size=0.3, random_state=self.random_state, stratify=y
        )
        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        print(f"‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É")

    def select_top_features(self):
        print(f"\nüîÑ === –ï–¢–ê–ü 0.5: –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö ===")
        importance_model = XGBClassifier(**self.optimal_params)
        importance_model.fit(self.X_train_scaled, self.y_train)
        feature_importance = importance_model.feature_importances_
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)
        print(f"üìä –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å —É—Å—ñ—Ö –æ–∑–Ω–∞–∫:")
        for i, (_, row) in enumerate(importance_df.iterrows(), 1):
            print(f"  {i:2d}. {row['feature']:<35} {row['importance']:.6f}")
        self.top_feature_names = importance_df.head(self.top_features_count)['feature'].tolist()
        self.feature_importance_scores = importance_df.head(self.top_features_count)
        self.top_feature_indices = [self.feature_names.index(feature) for feature in self.top_feature_names]
        self.X_train_top = self.X_train_scaled[:, self.top_feature_indices]
        self.X_test_top = self.X_test_scaled[:, self.top_feature_indices]
        print(f"‚úÖ –î–∞–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω—ñ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Ç–æ–ø-{self.top_features_count} –æ–∑–Ω–∞–∫–∞–º–∏")

    def test_feature_combination(self, feature_indices, combination_size):
        X_train_combo = self.X_train_top[:, feature_indices]
        X_test_combo = self.X_test_top[:, feature_indices]
        feature_combo_names = [self.top_feature_names[i] for i in feature_indices]
        model = XGBClassifier(**self.optimal_params)
        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)
        cv_f1_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='f1')
        cv_auc_roc_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='roc_auc')
        cv_auc_pr_scores = cross_val_score(model, X_train_combo, self.y_train, cv=cv_strategy, scoring='average_precision')
        model.fit(X_train_combo, self.y_train)
        y_pred = model.predict(X_test_combo)
        y_pred_proba = model.predict_proba(X_test_combo)[:, 1]
        metrics = {
            'combination_size': combination_size,
            'feature_indices': feature_indices,
            'feature_names': feature_combo_names,
            'feature_names_str': ' + '.join(feature_combo_names),
            'cv_f1_mean': cv_f1_scores.mean(),
            'cv_f1_std': cv_f1_scores.std(),
            'cv_auc_roc_mean': cv_auc_roc_scores.mean(),
            'cv_auc_roc_std': cv_auc_roc_scores.std(),
            'cv_auc_pr_mean': cv_auc_pr_scores.mean(),
            'cv_auc_pr_std': cv_auc_pr_scores.std(),
            'test_f1': f1_score(self.y_test, y_pred),
            'test_accuracy': accuracy_score(self.y_test, y_pred),
            'test_precision': precision_score(self.y_test, y_pred),
            'test_recall': recall_score(self.y_test, y_pred),
            'test_auc_roc': roc_auc_score(self.y_test, y_pred_proba),
            'test_auc_pr': average_precision_score(self.y_test, y_pred_proba),
            'overfitting_gap_f1': cv_f1_scores.mean() - f1_score(self.y_test, y_pred),
            'overfitting_gap_auc_pr': cv_auc_pr_scores.mean() - average_precision_score(self.y_test, y_pred_proba)
        }
        return metrics

    def analyze_all_combinations(self):
        print(f"\nüîÑ === –ï–¢–ê–ü 1: –ê–ù–ê–õ–Ü–ó –í–°–Ü–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –¢–û–ü-{self.top_features_count} –û–ó–ù–ê–ö ===")
        n_features = self.top_features_count
        total_combinations = 2**n_features - 1
        print(f"üî¢ –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {total_combinations}")
        print(f"‚ö° –¢–æ–ø –æ–∑–Ω–∞–∫–∏: {', '.join(self.top_feature_names)}")
        max_combination_size = n_features
        start_time = time.time()
        processed = 0
        for combination_size in range(1, max_combination_size + 1):
            print(f"\nüìä –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –∑ {combination_size} –æ–∑–Ω–∞–∫...")
            combinations = list(itertools.combinations(range(n_features), combination_size))
            n_combinations = len(combinations)
            print(f"üî¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {n_combinations}")
            for i, feature_indices in enumerate(combinations):
                if i % max(1, n_combinations // 10) == 0:
                    progress = (i / n_combinations) * 100
                    print(f"  üìà –ü—Ä–æ–≥—Ä–µ—Å: {progress:.1f}% ({i}/{n_combinations})")
                try:
                    metrics = self.test_feature_combination(feature_indices, combination_size)
                    self.results.append(metrics)
                    processed += 1
                except Exception as e:
                    print(f"  ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–ª—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó {feature_indices}: {e}")
                    continue
        total_time = time.time() - start_time
        print(f"\n‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –û–±—Ä–æ–±–ª–µ–Ω–æ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {processed}")
        self.results_df = pd.DataFrame(self.results)
        for size in range(1, max_combination_size + 1):
            size_results = self.results_df[self.results_df['combination_size'] == size]
            if not size_results.empty:
                best_idx = size_results['test_auc_pr'].idxmax()
                self.best_combinations[size] = self.results_df.loc[best_idx]

        # === –î–û–î–ê–ù–û: –ü–æ–≤–Ω–∏–π –ø–µ—Ä–µ–±—ñ—Ä –¥–ª—è –∑–∞–ª–∏—à–µ–Ω–∏—Ö –æ–∑–Ω–∞–∫ ===
        print(f"\nüîÑ === –ï–¢–ê–ü 1.5: –ü–û–í–ù–ò–ô –ü–ï–†–ï–ë–Ü–† –î–õ–Ø –ó–ê–õ–ò–®–ï–ù–ò–• –û–ó–ù–ê–ö ===")
        all_features = list(self.feature_names)
        top_set = set(self.top_feature_names)
        rest_features = [f for f in all_features if f not in top_set]
        print(f"–ó–∞–ª–∏—à–µ–Ω—ñ –æ–∑–Ω–∞–∫–∏: {rest_features}")
        self.rest_results = []
        if rest_features:
            rest_indices = [self.feature_names.index(f) for f in rest_features]
            n_rest = len(rest_features)
            for combination_size in range(1, n_rest + 1):
                print(f"\nüìä –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –∑ {combination_size} –∑–∞–ª–∏—à–µ–Ω–∏—Ö –æ–∑–Ω–∞–∫...")
                combinations = list(itertools.combinations(range(n_rest), combination_size))
                n_combinations = len(combinations)
                print(f"üî¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {n_combinations}")
                for i, feature_indices in enumerate(combinations):
                    if i % max(1, n_combinations // 10) == 0:
                        progress = (i / n_combinations) * 100
                        print(f"  üìà –ü—Ä–æ–≥—Ä–µ—Å: {progress:.1f}% ({i}/{n_combinations})")
                    try:
                        indices = [rest_indices[idx] for idx in feature_indices]
                        feature_names = [rest_features[idx] for idx in feature_indices]
                        X_train_rest = self.X_train_scaled[:, indices]
                        X_test_rest = self.X_test_scaled[:, indices]
                        model = XGBClassifier(**self.optimal_params)
                        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)
                        cv_f1_scores = cross_val_score(model, X_train_rest, self.y_train, cv=cv_strategy, scoring='f1')
                        cv_auc_roc_scores = cross_val_score(model, X_train_rest, self.y_train, cv=cv_strategy, scoring='roc_auc')
                        cv_auc_pr_scores = cross_val_score(model, X_train_rest, self.y_train, cv=cv_strategy, scoring='average_precision')
                        model.fit(X_train_rest, self.y_train)
                        y_pred = model.predict(X_test_rest)
                        y_pred_proba = model.predict_proba(X_test_rest)[:, 1]
                        metrics = {
                            'combination_size': len(feature_names),
                            'feature_indices': indices,
                            'feature_names': feature_names,
                            'feature_names_str': ' + '.join(feature_names),
                            'cv_f1_mean': cv_f1_scores.mean(),
                            'cv_f1_std': cv_f1_scores.std(),
                            'cv_auc_roc_mean': cv_auc_roc_scores.mean(),
                            'cv_auc_roc_std': cv_auc_roc_scores.std(),
                            'cv_auc_pr_mean': cv_auc_pr_scores.mean(),
                            'cv_auc_pr_std': cv_auc_pr_scores.std(),
                            'test_f1': f1_score(self.y_test, y_pred),
                            'test_accuracy': accuracy_score(self.y_test, y_pred),
                            'test_precision': precision_score(self.y_test, y_pred),
                            'test_recall': recall_score(self.y_test, y_pred),
                            'test_auc_roc': roc_auc_score(self.y_test, y_pred_proba),
                            'test_auc_pr': average_precision_score(self.y_test, y_pred_proba),
                            'overfitting_gap_f1': cv_f1_scores.mean() - f1_score(self.y_test, y_pred),
                            'overfitting_gap_auc_pr': cv_auc_pr_scores.mean() - average_precision_score(self.y_test, y_pred_proba)
                        }
                        self.rest_results.append(metrics)
                    except Exception as e:
                        print(f"  ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–ª—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó {feature_names}: {e}")
                        continue
            self.rest_results_df = pd.DataFrame(self.rest_results)
            print(f"‚úÖ –ü–æ–≤–Ω–∏–π –ø–µ—Ä–µ–±—ñ—Ä –¥–ª—è –∑–∞–ª–∏—à–µ–Ω–∏—Ö –æ–∑–Ω–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        else:
            self.rest_results_df = pd.DataFrame()

    def _plot_aucpr_vs_num_features(self):
        """Scatter plot: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ vs AUC-PR"""
        plt.figure(figsize=(12, 7))
        x = self.results_df['combination_size']
        y = self.results_df['test_auc_pr']
        plt.scatter(x, y, alpha=0.5, c=x, cmap='viridis', edgecolor='k')
        plt.xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ —É –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó', fontsize=14)
        plt.ylabel('AUC-PR (test_auc_pr)', fontsize=14)
        plt.title('–ó–∞–ª–µ–∂–Ω—ñ—Å—Ç—å AUC-PR –≤—ñ–¥ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫ —É –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó', fontsize=16, fontweight='bold')
        # –î–æ–¥–∞—î–º–æ padding –ø–æ –æ—Å—ñ Y
        y_min, y_max = y.min(), y.max()
        y_range = y_max - y_min
        pad = y_range * 0.05 if y_range > 0 else 0.01
        plt.xlim(0.5, self.top_features_count + 0.5)
        plt.ylim(y_min - pad, y_max + pad)
        plt.xticks(range(1, self.top_features_count + 1))
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/aucpr_vs_num_features.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_aucpr_vs_num_features_extended(self):
        """Scatter plot: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ vs AUC-PR (—Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π)"""
        plt.figure(figsize=(12, 7))
        # –û—Å–Ω–æ–≤–Ω—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó
        x1 = self.results_df['combination_size']
        y1 = self.results_df['test_auc_pr']
        # –†–æ–∑—à–∏—Ä–µ–Ω—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó
        x2 = self.extended_results_df['combination_size'] if hasattr(self, 'extended_results_df') else []
        y2 = self.extended_results_df['test_auc_pr'] if hasattr(self, 'extended_results_df') else []
        plt.scatter(x1, y1, alpha=0.5, c=x1, cmap='viridis', edgecolor='k', label='–ö–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Ç–æ–ø–æ–≤–∏—Ö –æ–∑–Ω–∞–∫')
        if len(x2) > 0:
            plt.scatter(x2, y2, alpha=0.9, c='red', marker='*', s=120, label='–†–æ–∑—à–∏—Ä–µ–Ω—ñ –Ω–∞–±–æ—Ä–∏ (top + 1)')
        plt.xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ —É –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó', fontsize=14)
        plt.ylabel('AUC-PR (test_auc_pr)', fontsize=14)
        plt.title('AUC-PR –¥–ª—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π —Ç–æ–ø–æ–≤–∏—Ö —Ç–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏—Ö –Ω–∞–±–æ—Ä—ñ–≤ –æ–∑–Ω–∞–∫', fontsize=16, fontweight='bold')
        # –î–æ–¥–∞—î–º–æ padding –ø–æ –æ—Å—ñ Y
        all_y = pd.concat([y1, y2]) if len(y2) > 0 else y1
        y_min, y_max = all_y.min(), all_y.max()
        y_range = y_max - y_min
        pad = y_range * 0.05 if y_range > 0 else 0.01
        plt.xlim(0.5, self.top_features_count + len(x2) + 0.5)
        plt.ylim(y_min - pad, y_max + pad)
        plt.xticks(range(1, self.top_features_count + len(x2) + 1))
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/aucpr_vs_num_features_extended.png', dpi=300, bbox_inches='tight')
        plt.close()

    def create_visualizations(self):
        print(f"\nüîÑ === –ï–¢–ê–ü 2: –°–¢–í–û–†–ï–ù–ù–Ø –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–ô ===")
        print(f"üñºÔ∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ matplotlib backend 'Agg' (non-interactive)")
        try:
            print(f"  üìä –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö...")
            self._plot_metrics_by_size()
            print(f"  üèÜ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ —Ç–æ–ø –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π...")
            self._plot_top_combinations()
            print(f"  üéØ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫...")
            self._plot_individual_features()
            print(f"  üî• –°—Ç–≤–æ—Ä–µ–Ω–Ω—è heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ—ó...")
            self._plot_metrics_correlation()
            print(f"  üìà –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è...")
            self._plot_overfitting_analysis()
            print(f"  üü¢ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è scatter-–≥—Ä–∞—Ñ—ñ–∫–∞ AUC-PR vs –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫...")
            self._plot_aucpr_vs_num_features()
            # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–ª—è –∑–∞–ª–∏—à–µ–Ω–∏—Ö –æ–∑–Ω–∞–∫
            if not self.rest_results_df.empty:
                print(f"  üü† –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –¥–ª—è –∑–∞–ª–∏—à–µ–Ω–∏—Ö –æ–∑–Ω–∞–∫...")
                self._plot_metrics_by_size_rest()
                self._plot_top_combinations_rest()
                self._plot_individual_features_rest()
                self._plot_metrics_correlation_rest()
                self._plot_overfitting_analysis_rest()
                self._plot_aucpr_vs_num_features_rest()
            print(f"‚úÖ –í—Å—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ!")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π: {e}")
            print(f"‚ö†Ô∏è –ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ –±–µ–∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π...")
            return False
        return True

    def _plot_metrics_by_size(self):
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('–ê–Ω–∞–ª—ñ–∑ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –æ–∑–Ω–∞–∫', fontsize=16, fontweight='bold')
        metrics = ['test_f1', 'test_auc_pr', 'test_auc_roc', 'overfitting_gap_auc_pr']
        titles = ['F1 Score', 'AUC-PR (Primary)', 'AUC-ROC', 'Overfitting Gap AUC-PR (CV - Test)']
        for i, (metric, title) in enumerate(zip(metrics, titles)):
            ax = axes[i//2, i%2]
            sizes = sorted(self.results_df['combination_size'].unique())
            data_by_size = [self.results_df[self.results_df['combination_size'] == size][metric]
                           for size in sizes]
            bp = ax.boxplot(data_by_size, labels=sizes, patch_artist=True)
            colors = plt.cm.viridis(np.linspace(0, 1, len(sizes)))
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            ax.set_title(title, fontweight='bold')
            ax.set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ –≤ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó')
            ax.set_ylabel(title)
            ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/metrics_by_combination_size.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_top_combinations(self):
        top_combinations = self.results_df.nlargest(10, 'test_auc_pr')
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        bars1 = ax1.barh(range(len(top_combinations)), top_combinations['test_auc_pr'],
                        color=plt.cm.viridis(np.linspace(0, 1, len(top_combinations))))
        ax1.set_yticks(range(len(top_combinations)))
        ax1.set_yticklabels([f"{row['combination_size']} –æ–∑–Ω–∞–∫:\n{row['feature_names_str'][:50]}..."
                            if len(row['feature_names_str']) > 50
                            else f"{row['combination_size']} –æ–∑–Ω–∞–∫:\n{row['feature_names_str']}"
                            for _, row in top_combinations.iterrows()], fontsize=10)
        ax1.set_xlabel('Test AUC-PR Score')
        ax1.set_title('–¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π –æ–∑–Ω–∞–∫ (AUC-PR)', fontweight='bold')
        ax1.grid(True, alpha=0.3)
        for i, bar in enumerate(bars1):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2,
                    f'{width:.4f}', ha='left', va='center', fontweight='bold')
        x_pos = np.arange(len(top_combinations))
        width = 0.35
        bars1 = ax2.bar(x_pos - width/2, top_combinations['cv_auc_pr_mean'], width,
                       label='CV AUC-PR Score', alpha=0.8, color='lightblue')
        bars2 = ax2.bar(x_pos + width/2, top_combinations['test_auc_pr'], width,
                       label='Test AUC-PR Score', alpha=0.8, color='lightcoral')
        ax2.set_xlabel('–ö–æ–º–±—ñ–Ω–∞—Ü—ñ—è –æ–∑–Ω–∞–∫')
        ax2.set_ylabel('AUC-PR Score')
        ax2.set_title('CV vs Test AUC-PR Score –¥–ª—è —Ç–æ–ø-10 –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π', fontweight='bold')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels([f"{i+1}" for i in range(len(top_combinations))])
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/top_combinations.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_individual_features(self):
        single_features = self.results_df[self.results_df['combination_size'] == 1].copy()
        single_features = single_features.sort_values('test_auc_pr', ascending=True)
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
        bars = ax1.barh(range(len(single_features)), single_features['test_auc_pr'],
                       color=plt.cm.RdYlGn(np.linspace(0.3, 1, len(single_features))))
        ax1.set_yticks(range(len(single_features)))
        ax1.set_yticklabels(single_features['feature_names_str'], fontsize=12)
        ax1.set_xlabel('Test AUC-PR Score')
        ax1.set_title('–†–µ–π—Ç–∏–Ω–≥ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫ (AUC-PR)', fontweight='bold', fontsize=14)
        ax1.grid(True, alpha=0.3)
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2,
                    f'{width:.4f}', ha='left', va='center', fontweight='bold')
        top_20 = self.results_df.nlargest(20, 'test_auc_pr')
        feature_counts = {}
        for _, row in top_20.iterrows():
            for feature in row['feature_names']:
                feature_counts[feature] = feature_counts.get(feature, 0) + 1
        features_sorted = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)
        features, counts = zip(*features_sorted)
        bars2 = ax2.bar(range(len(features)), counts,
                       color=plt.cm.plasma(np.linspace(0, 1, len(features))))
        ax2.set_xticks(range(len(features)))
        ax2.set_xticklabels(features, rotation=45, ha='right')
        ax2.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–∏ –≤ —Ç–æ–ø-20')
        ax2.set_title('–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–∏ –æ–∑–Ω–∞–∫ –≤ –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è—Ö', fontweight='bold', fontsize=14)
        ax2.grid(True, alpha=0.3)
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{int(height)}', ha='center', va='bottom', fontweight='bold')
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/individual_features_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_metrics_correlation(self):
        metrics_cols = ['test_f1', 'test_auc_pr', 'test_auc_roc', 'test_accuracy',
                       'test_precision', 'test_recall', 'cv_auc_pr_mean', 'overfitting_gap_auc_pr']
        correlation_matrix = self.results_df[metrics_cols].corr()
        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": .8}, fmt='.3f')
        plt.title('–ö–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —è–∫–æ—Å—Ç—ñ', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/metrics_correlation.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_overfitting_analysis(self):
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        scatter = ax1.scatter(self.results_df['cv_auc_pr_mean'], self.results_df['test_auc_pr'],
                            c=self.results_df['combination_size'], cmap='viridis', alpha=0.6)
        min_val = min(self.results_df['cv_auc_pr_mean'].min(), self.results_df['test_auc_pr'].min())
        max_val = max(self.results_df['cv_auc_pr_mean'].max(), self.results_df['test_auc_pr'].max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
        ax1.set_xlabel('CV AUC-PR Score')
        ax1.set_ylabel('Test AUC-PR Score')
        ax1.set_title('CV vs Test AUC-PR Score', fontweight='bold')
        ax1.grid(True, alpha=0.3)
        cbar = plt.colorbar(scatter, ax=ax1)
        cbar.set_label('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫')
        ax2.hist(self.results_df['overfitting_gap_auc_pr'], bins=30, alpha=0.7, color='orange', edgecolor='black')
        ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='–ù–µ–º–∞—î –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è')
        ax2.axvline(self.results_df['overfitting_gap_auc_pr'].mean(), color='blue', linestyle='-',
                   linewidth=2, label=f'–°–µ—Ä–µ–¥–Ω—î: {self.results_df["overfitting_gap_auc_pr"].mean():.4f}')
        ax2.set_xlabel('Overfitting Gap AUC-PR (CV - Test)')
        ax2.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        ax2.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è (AUC-PR)', fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/overfitting_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def generate_report(self):
        print(f"\nüîÑ === –ï–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ó–í–Ü–¢–£ ===")
        self.results_df.to_csv(f'{self.results_dir}/all_combinations_results.csv', index=False)
        top_10 = self.results_df.nlargest(10, 'test_auc_pr')
        top_10.to_csv(f'{self.results_dir}/top_10_combinations.csv', index=False)
        report_path = f'{self.results_dir}/analysis_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# üî¨ –ó–í–Ü–¢ –ê–ù–ê–õ–Ü–ó–£ –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –û–ó–ù–ê–ö\n\n")
            f.write("## üìä –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è\n")
            f.write(f"- –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ —É –¥–∞—Ç–∞—Å–µ—Ç—ñ: {len(self.feature_names)}\n")
            f.write(f"- –¢–æ–ø –æ–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É: {self.top_features_count}\n")
            f.write(f"- –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {len(self.results_df)}\n")
            f.write(f"- –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ XGBoost\n")
            f.write(f"- –û—Å–Ω–æ–≤–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó: AUC-PR (Area Under Precision-Recall Curve)\n\n")
            f.write("## üèÜ –í–∏–±—Ä–∞–Ω—ñ —Ç–æ–ø –æ–∑–Ω–∞–∫–∏ (–∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é XGBoost)\n")
            for i, (_, row) in enumerate(self.feature_importance_scores.iterrows(), 1):
                f.write(f"{i}. **{row['feature']}** - –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å: {row['importance']:.6f}\n")
            f.write("\n")
            f.write("## üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ XGBoost\n")
            for param, value in self.optimal_params.items():
                f.write(f"- {param}: {value}\n")
            f.write("\n")
            f.write("## üèÜ –¢–û–ü-5 –ù–ê–ô–ö–†–ê–©–ò–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô (–∑–∞ AUC-PR)\n\n")
            top_5 = self.results_df.nlargest(5, 'test_auc_pr')
            for i, (_, row) in enumerate(top_5.iterrows(), 1):
                f.write(f"### {i}. –ö–æ–º–±—ñ–Ω–∞—Ü—ñ—è –∑ {row['combination_size']} –æ–∑–Ω–∞–∫\n")
                f.write(f"- **–û–∑–Ω–∞–∫–∏**: {row['feature_names_str']}\n")
                f.write(f"- **Test AUC-PR**: {row['test_auc_pr']:.6f} (Primary)\n")
                f.write(f"- **Test F1 Score**: {row['test_f1']:.6f}\n")
                f.write(f"- **Test AUC-ROC**: {row['test_auc_roc']:.6f}\n")
                f.write(f"- **Test Accuracy**: {row['test_accuracy']:.6f}\n")
                f.write(f"- **CV AUC-PR**: {row['cv_auc_pr_mean']:.6f} ¬± {row['cv_auc_pr_std']:.6f}\n")
                f.write(f"- **Overfitting Gap (AUC-PR)**: {row['overfitting_gap_auc_pr']:.6f}\n\n")
            single_features = self.results_df[self.results_df['combination_size'] == 1].nlargest(5, 'test_auc_pr')
            f.write("## ü•á –¢–û–ü-5 –Ü–ù–î–ò–í–Ü–î–£–ê–õ–¨–ù–ò–• –û–ó–ù–ê–ö (–∑–∞ AUC-PR)\n\n")
            for i, (_, row) in enumerate(single_features.iterrows(), 1):
                f.write(f"### {i}. {row['feature_names_str']}\n")
                f.write(f"- **Test AUC-PR**: {row['test_auc_pr']:.6f} (Primary)\n")
                f.write(f"- **Test F1 Score**: {row['test_f1']:.6f}\n")
                f.write(f"- **Test AUC-ROC**: {row['test_auc_roc']:.6f}\n")
                f.write(f"- **Test Accuracy**: {row['test_accuracy']:.6f}\n\n")
            f.write("## üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–û–ó–ú–Ü–†–ê–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô\n\n")
            f.write("| –†–æ–∑–º—ñ—Ä | –ö—ñ–ª—å–∫—ñ—Å—Ç—å | –°–µ—Ä–µ–¥–Ω—ñ–π AUC-PR | –ù–∞–π–∫—Ä–∞—â–∏–π AUC-PR | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è |\n")
            f.write("|--------|-----------|-----------------|------------------|-----------------------|\n")
            for size in sorted(self.results_df['combination_size'].unique()):
                size_data = self.results_df[self.results_df['combination_size'] == size]
                f.write(f"| {size} | {len(size_data)} | {size_data['test_auc_pr'].mean():.6f} | {size_data['test_auc_pr'].max():.6f} | {size_data['test_auc_pr'].std():.6f} |\n")
            best_overall = self.results_df.loc[self.results_df['test_auc_pr'].idxmax()]
            best_single = single_features.iloc[0]
            f.write("\n## üéØ –ö–õ–Æ–ß–û–í–Ü –í–ò–°–ù–û–í–ö–ò\n\n")
            f.write("### 1. –ù–∞–π–∫—Ä–∞—â–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è\n")
            f.write(f"- **{best_overall['combination_size']} –æ–∑–Ω–∞–∫**: {best_overall['feature_names_str']}\n")
            f.write(f"- **AUC-PR**: {best_overall['test_auc_pr']:.6f} (Primary)\n")
            f.write(f"- **F1 Score**: {best_overall['test_f1']:.6f}\n")
            improvement = ((best_overall['test_auc_pr'] / best_single['test_auc_pr'] - 1) * 100)
            f.write(f"- –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤—ñ–¥–Ω–æ—Å–Ω–æ –Ω–∞–π–∫—Ä–∞—â–æ—ó —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–æ—ó –æ–∑–Ω–∞–∫–∏: {improvement:.2f}%\n\n")
            f.write("### 2. –ù–∞–π–∫—Ä–∞—â–∞ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∞ –æ–∑–Ω–∞–∫–∞\n")
            f.write(f"- **{best_single['feature_names_str']}**\n")
            f.write(f"- **AUC-PR**: {best_single['test_auc_pr']:.6f} (Primary)\n")
            f.write(f"- **F1 Score**: {best_single['test_f1']:.6f}\n\n")
            f.write("### 3. –ê–Ω–∞–ª—ñ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è\n")
            f.write(f"- –°–µ—Ä–µ–¥–Ω—ñ–π overfitting gap (AUC-PR): {self.results_df['overfitting_gap_auc_pr'].mean():.6f}\n")
            no_overfitting = (self.results_df['overfitting_gap_auc_pr'] <= 0).sum()
            f.write(f"- –ö–æ–º–±—ñ–Ω–∞—Ü—ñ–π –±–µ–∑ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è: {no_overfitting} –∑ {len(self.results_df)}\n\n")
            f.write("### 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó\n")
            if best_overall['combination_size'] == 1:
                f.write("- –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ª–∏—à–µ –æ–¥–Ω—É –æ–∑–Ω–∞–∫—É - —Ü–µ —Å–≤—ñ–¥—á–∏—Ç—å –ø—Ä–æ –≤–∏—Å–æ–∫—É —è–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö\n")
            else:
                f.write(f"- –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {best_overall['combination_size']}\n")
                f.write("- –ö–æ–º–±—ñ–Ω—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ –¥–∞—î –∑–Ω–∞—á–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n")
            if self.results_df['overfitting_gap_auc_pr'].mean() > 0.02:
                f.write("- –ú–æ–¥–µ–ª—å —Å—Ö–∏–ª—å–Ω–∞ –¥–æ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è - –≤–∞—Ä—Ç–æ –∑–±—ñ–ª—å—à–∏—Ç–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—é\n")
            else:
                f.write("- –ú–æ–¥–µ–ª—å –¥–æ–±—Ä–µ –≥–µ–Ω–µ—Ä–∞–ª—ñ–∑—É—î - –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—ñ–¥—ñ–±—Ä–∞–Ω—ñ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ\n")
            f.write("\n## üìÅ –°—Ç–≤–æ—Ä–µ–Ω—ñ —Ñ–∞–π–ª–∏\n")
            f.write("- `all_combinations_results.csv` - –ü–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—Å—ñ—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π\n")
            f.write("- `top_10_combinations.csv` - –¢–æ–ø-10 –Ω–∞–π–∫—Ä–∞—â–∏—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π (–∑–∞ AUC-PR)\n")
            f.write("- `feature_importance_all.csv` - –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫\n")
            f.write("- `top_features_selected.csv` - –í–∏–±—Ä–∞–Ω—ñ —Ç–æ–ø –æ–∑–Ω–∞–∫–∏\n")
            f.write("- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —É —Ñ–æ—Ä–º–∞—Ç—ñ PNG\n")
        print(f"üìÑ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_path}")
        print(f"üíæ CSV —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –ø–∞–ø—Ü—ñ: {self.results_dir}/")

    def run_analysis(self):
        print(f"üöÄ === –ü–û–ß–ê–¢–û–ö –ê–ù–ê–õ–Ü–ó–£ –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô –û–ó–ù–ê–ö ===")
        start_time = time.time()
        try:
            self.load_and_prepare_data()
            self.select_top_features()
            self.analyze_all_combinations()
            visualization_success = self.create_visualizations()
            if not visualization_success:
                print(f"‚ö†Ô∏è –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω—ñ —á–µ—Ä–µ–∑ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏")
                print(f"üìä –ê–ª–µ –≤—Å—ñ –¥–∞–Ω—ñ —Ç–∞ –∑–≤—ñ—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ!")
            self.generate_report()
            total_time = time.time() - start_time
            print(f"\n‚úÖ === –ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–Ü–®–ù–û ===")
            print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–æ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π: {len(self.results_df)}")
            print(f"üèÜ –ù–∞–π–∫—Ä–∞—â–∏–π AUC-PR Score: {self.results_df['test_auc_pr'].max():.6f}")
            print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {self.results_dir}/")
            print(f"\nü•á –¢–û–ü-3 –ù–ê–ô–ö–†–ê–©–ò–• –ö–û–ú–ë–Ü–ù–ê–¶–Ü–ô (–∑–∞ AUC-PR):")
            top_3 = self.results_df.nlargest(3, 'test_auc_pr')
            for i, (_, row) in enumerate(top_3.iterrows(), 1):
                print(f"{i}. {row['feature_names_str']} (AUC-PR: {row['test_auc_pr']:.6f})")
        except Exception as e:
            print(f"‚ùå –ü–û–ú–ò–õ–ö–ê: {e}")
            raise

if __name__ == '__main__':
    analyzer = FeatureCombinationAnalyzer(
        data_path=r'D:\PROJECTs\MY\ScientificCalculations\SC\ScientificCalculations\PaperS\Paper4\preprocessed_data2.csv',
        random_state=42,
        top_features_count=12
    )
    analyzer.load_and_prepare_data()
    analyzer.select_top_features()
    analyzer.analyze_all_combinations()
    analyzer.create_visualizations()  # –ó–∞ –ø–æ—Ç—Ä–µ–±–∏
    analyzer.generate_report()        # –ó–∞ –ø–æ—Ç—Ä–µ–±–∏