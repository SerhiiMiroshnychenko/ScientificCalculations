# Опис функціональності скрипта `compare_rfe_greedy_xgb_backward_boruta_xgbbackward_aucpr_curve.py`

## Постановка задачі

У сучасних задачах машинного навчання, особливо при роботі з високовимірними даними, надзвичайно важливим є вибір релевантних ознак (feature selection), які забезпечують найкращу якість класифікації або регресії. Відбір ознак дозволяє не лише підвищити точність моделей, а й зменшити ризик перенавчання, прискорити обчислення та покращити інтерпретованість результатів. У даній роботі ставиться задача порівняння ефективності різних алгоритмів відбору ознак для задачі бінарної класифікації на основі метрики AUC-PR (Area Under the Precision-Recall Curve).

## Методологія розв’язання

Для вирішення поставленої задачі було розроблено програмний скрипт, який реалізує повний цикл порівняння шести підходів до відбору ознак: рекурсивного виключення ознак (RFE), жадібного покрокового додавання ознак (Greedy Forward Selection), відбору за важливістю ознак у моделі XGBoost, жадібного покрокового видалення ознак (Backward Elimination), алгоритму Boruta з використанням XGBoost як базового класифікатора, а також зворотного відбору ознак на основі важливості, визначеної вбудованим механізмом XGBoost (Backward by XGBoost importance).

На першому етапі здійснюється попередня обробка даних, що включає видалення нечислових ознак, об’єднання циклічних ознак у модулі, стандартизацію та розбиття на тренувальну і тестову вибірки. Далі для кожного з методів формується послідовність підмножин ознак, для яких тренується модель XGBoost із фіксованими гіперпараметрами. Для кожної підмножини обчислюється значення метрики AUC-PR на тестовій вибірці. У випадку RFE ознаки додаються у порядку їх важливості, визначеної методом рекурсивного виключення. Greedy Forward Selection реалізує покрокове додавання ознак, кожного разу обираючи ту, яка дає найбільший приріст метрики. Відбір за важливістю XGBoost здійснюється шляхом послідовного додавання ознак у порядку їхньої важливості, визначеної вбудованим механізмом моделі. Backward Elimination починається з повного набору ознак і на кожному кроці видаляє одну ознаку, видалення якої найменше погіршує якість моделі. Алгоритм Boruta порівнює важливість справжніх ознак із тіньовими, залишаючи лише статистично значущі, після чого для всіх можливих підмножин відібраних Boruta ознак також обчислюється AUC-PR. Додатково реалізовано метод зворотного відбору ознак на основі важливості XGBoost, при якому на кожному кроці з повного набору ознак видаляється одна найменш важлива ознака згідно з рейтингом, побудованим вбудованим механізмом моделі.

Результати для кожного методу зберігаються у вигляді CSV-файлів, де для кожної підмножини ознак фіксується її склад та відповідне значення метрики. Для візуального порівняння будується об’єднаний графік залежності AUC-PR від кількості ознак у діапазоні від 12 до 24, на якому кожен метод представлений окремою кривою з відповідним кольоровим маркуванням. Такий підхід дозволяє не лише кількісно оцінити ефективність різних стратегій відбору ознак, а й виявити оптимальні комбінації ознак для побудови моделей із максимальною прогностичною здатністю. 

> **Примітка щодо методу Boruta:**
> Максимальна кількість ознак, що відбирається методом Boruta, може бути меншою за повний набір доступних ознак. Це пов’язано з тим, що Boruta спеціально розроблений для залишення лише статистично значущих ознак, відкидаючи всі інші. У цьому дослідженні Boruta визначила важливими лише 22 із 24 ознак. Тому результати для Boruta не містять повного набору ознак, на відміну від інших методів. Це очікувана поведінка, яка відображає консервативний характер алгоритму Boruta. 