{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Нижче — детальний аналіз кожного з переліку методів з точки зору їх доцільності для вашої задачі (виявлення впливу ознак на бінарну ціль «успішне/неуспішне замовлення»), а також кластеризація методів за математичною суттю (щоб визначити дублювання).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Welch’s t-test (p-value)\n",
    "\n",
    "- **Призначення**: перевірити, чи відрізняються середні значення числової ознаки в двох незалежних групах (успішні vs. неуспішні).\n",
    "- **Переваги**: уважається більш стабільним за стандартний t-тест при нерівній дисперсії та розмірах груп.\n",
    "- **Обмеження**:\n",
    "  - Потребує приблизно нормального розподілу в обох групах (але для великих «n» <u>частково непоколивий</u> через ЦПТ).\n",
    "  - Не застосовується до категоріальних ознак без попереднього числового кодування.\n",
    "  - Дає тільки p-значення, але не «розмір ефекту».\n",
    "\n",
    "**Висновок**: корисний для швидкого скринінгу числових ознак, але слід доповнювати effect-size та перевіркою припущень.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Mann–Whitney U-test (p-value)\n",
    "\n",
    "- **Призначення**: непараметричний тест на відмінність розподілу двох груп.\n",
    "- **Переваги**:\n",
    "  - Не вимагає нормальності чи рівності дисперсій.\n",
    "  - Чутливий до зсуву медіан або загального «розкиду» двох підвибірок.\n",
    "- **Обмеження**:\n",
    "  - Інтерпретація p-значення менш прозора: тестує, чи значно відрізняється випадкова величина з однієї групи від випадкової величини з іншої (не строго медіани).\n",
    "  - Не дає розміру ефекту (але можливий розрахунок rank-biserial correlation).\n",
    "\n",
    "**Висновок**: рекомендований для числових ознак із сильно невідповідними нормальним припущенням розподілами.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Cohen’s d\n",
    "\n",
    "- **Призначення**: стандартний розмір ефекту (різниця середніх, поділена на pooled SD).\n",
    "- **Переваги**: дає інтуїтивну шкалу «малий/середній/великий» ефект.\n",
    "- **Обмеження**:\n",
    "  - Припускає приблизну нормальність.\n",
    "  - Все одно потребує двох окремих розподілів (успішні vs. неуспішні).\n",
    "\n",
    "**Висновок**: обов’язково використовувати спільно з t-тестом або ANOVA для оцінки практичної значущості.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Univariate AUC\n",
    "\n",
    "- **Призначення**: зводить кожну ознаку до одно-означного предиктора, рахує ROC-криву та площу під нею.\n",
    "- **Переваги**:\n",
    "  - Не потребує жодних припущень про розподіл.\n",
    "  - Чутливий до будь-яких зрушень розподілів чи розкиду.\n",
    "- **Обмеження**:\n",
    "  - Не дає напряму інформації про напрям (позитивний/негативний ефект).\n",
    "  - Для категоріальних ознак з багатьма рівнями може бути неінформативним без правильного перетворення.\n",
    "\n",
    "**Висновок**: універсальний скринер, але потребує наступного інтерпретаційного кроку (напрямко та shape of effect).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Information Value (IV)\n",
    "\n",
    "- **Призначення**: популярний у скорингу кредитів – бінінг числових ознак, розрахунок WOE (weight of evidence) та IV.\n",
    "- **Переваги**:\n",
    "  - Добре працює з категоріями та бінованими числовими.\n",
    "  - IV дає чіткий поріг (наприклад, IV>0.3 – сильний предиктор).\n",
    "- **Обмеження**:\n",
    "  - Потребує належного бінінгу (може «перебінювати» якщо даних мало в крайніх бінгах).\n",
    "  - Орієнтований на бінарну ціль; не підходить для безперервних тарґетів.\n",
    "\n",
    "**Висновок**: дуже корисний для швидкої оцінки «кредитоздатності» ознаки, але можна вважати варіантом інформаційного підходу, схожим на mutual information.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Mutual Information (MI)\n",
    "\n",
    "- **Призначення**: вимір залежності між двома змінними (числовою/категоріальною) без припущень про лінійність.\n",
    "- **Переваги**:\n",
    "  - Виявляє будь-яку залежність, не тільки монотонну.\n",
    "  - Підходить до змішаних типів ознак (після дискретизації для числових або без).\n",
    "- **Обмеження**:\n",
    "  - Для оцінки вимагає достатньо даних (оціночна нестабільність при малій «n»).\n",
    "  - Не дає напряму «позитив/негатив»— лише міру взаємної інформації.\n",
    "\n",
    "**Висновок**: універсальний, але схильний до нестабільного оцінювання, якщо ви дискретизуєте непродуманно. Частково дублює IV.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. ANOVA F-статистика\n",
    "\n",
    "- **Призначення**: загальне порівняння середніх більш ніж двох груп; у випадку двох груп еквівалентно квадрату t-статистики.\n",
    "- **Дублювання**:\n",
    "  - Для двох груп (успішні/неуспішні) F-тест ≈ (t-тест)\\².\n",
    "- **Висновок**: дублює t-тест (методи 1 і 14).\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Spearman correlation\n",
    "\n",
    "- **Призначення**: кореляція рангових значень (монотонна залежність).\n",
    "- **Переваги**:\n",
    "  - Чутлива до будь-яких монотонних залежностей.\n",
    "  - Менш чутлива до викидів, ніж Пірсон.\n",
    "- **Обмеження**:\n",
    "  - Для бінарної цілі (0/1) на практиці дає rank-biserial correlation; може бути менш інтуїтивною.\n",
    "\n",
    "**Висновок**: хороший непараметричний аналог Пірсона, варто включати для перевірки монотонних зв’язків.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Коєфіцієнт логістичної регресії\n",
    "\n",
    "- **Призначення**: Univariate або multivariate logistic regression — оцінює log-odds зміни при зміні ознаки на 1.\n",
    "- **Переваги**:\n",
    "  - Дає напряму «збільшення/зменшення ризику».\n",
    "  - Мультиваріантний варіант дозволяє контролювати інші ознаки.\n",
    "- **Обмеження**:\n",
    "  - Потрібна перевірка мультиколінеарності.\n",
    "  - Coefficient magnitude залежить від масштабу ознаки.\n",
    "\n",
    "**Висновок**: центральний метод для інтерпретації одночасного впливу багатьох ознак; у разі univariate аналізу — схожий на t-test/ANOVA/F-тест.\n",
    "\n",
    "---\n",
    "\n",
    "## 10–12. Feature Importance із деревних моделей\n",
    "\n",
    "| Метод                   | Принцип                              | Плюси                                           | Мінуси                                      |\n",
    "|-------------------------|--------------------------------------|-------------------------------------------------|---------------------------------------------|\n",
    "| **Decision Tree**       | зменшення невизначеності (Gini/Entropy) при сплітах | Простий, інтерпретований                       | Залежить від одного дерева → нестійкий      |\n",
    "| **Random Forest**       | середнє важливостей багатьох дерев   | Стабільніше, здатен виявити нелінійності        | Біас до категорій з багатьма рівнями        |\n",
    "| **XGBoost**             | градієнтний бустинг дерев             | Часто дає кращу якість, контроль regularization | Складніший для інтерпретації, теж біасний   |\n",
    "\n",
    "- **Дублювання**: усі три — на основі дерев, досить схожі; але зростаюча складність і стійкість RF та XGBoost дають різні профілі важливостей.\n",
    "- **Висновок**: рекомендую застосувати хоча б один ансамбль (RF або XGBoost) для комплексного урахування взаємодій і нелінійностей.\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Хі-квадрат тест\n",
    "\n",
    "- **Призначення**: тест незалежності для двох категоріальних змінних.\n",
    "- **Переваги**: простий, чітка інтерпретація.\n",
    "- **Обмеження**:\n",
    "  - Не підходить напряму до числових ознак (потребує бінінгу).\n",
    "  - Залежить від розміру категорій — багато дрібних рівнів зменшують потужність тесту.\n",
    "\n",
    "**Висновок**: основний інструмент для категоріальних ознак, але дублює загальну ідею MI (але дає p-value замість інформаційної міри).\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Pearson correlation\n",
    "\n",
    "- **Призначення**: лінійна кореляція між числовою ознакою та бінарною ціллю (point-biserial correlation).\n",
    "- **Дублювання**:\n",
    "  - Для двох груп t-тест та ANOVA дають ті самі p-значення.\n",
    "- **Висновок**: дублює методи 1 і 7, але може додавати просту міру напрямку та сили лінійної залежності.\n",
    "\n",
    "---\n",
    "\n",
    "## 15. Distance Correlation (dCor)\n",
    "\n",
    "- **Призначення**: вимір усіх типів залежностей (як лінійних, так і нелінійних).\n",
    "- **Переваги**:\n",
    "  - Чутливий до будь-яких видів залежностей, відмінний від нуля ↔ залежність ≠ незалежність.\n",
    "- **Обмеження**:\n",
    "  - Менш відомий, важче інтерпретувати величину.\n",
    "  - Обчислювально затратний для великих «n» (≈ 86 794).\n",
    "\n",
    "**Висновок**: корисний для вичерпного пошуку залежностей, але вартий лише за дуже потужного апаратного забезпечення.\n",
    "\n",
    "---\n",
    "\n",
    "## 16. HHG (Heller–Heller–Gorfine)\n",
    "\n",
    "- **Призначення**: непараметричний тест загальної залежності.\n",
    "- **Переваги**: виявляє як локальні, так і глобальні структури в даних.\n",
    "- **Обмеження**: обчислювально дуже затратний, складна інтерпретація p-значення.\n",
    "\n",
    "**Висновок**: метод «для крапкових» досліджень у невеликих підмножинах, але не для всього датасету.\n",
    "\n",
    "---\n",
    "\n",
    "## 17. Hoeffding’s D\n",
    "\n",
    "- **Призначення**: тест незалежності, чутливий до будь-якої залежності.\n",
    "- **Обмеження**: схожі на HHG — важко масштабувати й інтерпретувати.\n",
    "\n",
    "**Висновок**: дублює ідею dCor/HHG/MIC, але є рідко в практиці через обчислювальні складнощі.\n",
    "\n",
    "---\n",
    "\n",
    "## 18. Maximal Information Coefficient (MIC)\n",
    "\n",
    "- **Призначення**: шукає будь-які функціональні чи нефункціональні залежності за допомогою оптимального «грид-розбиття».\n",
    "- **Переваги**:\n",
    "  - Виявляє як лінійні, так і складні нефункціональні зв’язки.\n",
    "- **Обмеження**:\n",
    "  - Може створювати хибні покликання на залежність (overfitting гридів).\n",
    "  - Досить затратний для великого датасету.\n",
    "\n",
    "---\n",
    "\n",
    "##  Альтернативні «сімейства» / дублювання\n",
    "\n",
    "1. **t-test / ANOVA / Pearson correlation** (1, 7, 14)\n",
    "2. **Information Value / Mutual Information / χ²** (5, 6, 13)\n",
    "3. **Cohen’s d / p-value t-test** (3 & 1)\n",
    "4. **HHG / Hoeffding’s D / Distance Correlation / MIC** (15–18)\n",
    "5. **Decision Tree / Random Forest / XGBoost** (10–12)\n",
    "\n",
    "---\n",
    "\n",
    "## Рекомендації щодо підходу\n",
    "\n",
    "1. **Базовий скринінг**\n",
    "   - Для **числових ознак**: univariate AUC, Mann–Whitney, Cohen’s d.\n",
    "   - Для **категоріальних**: χ², IV.\n",
    "2. **Інформаційні методи**\n",
    "   - Mutual Information (як універсальний) + Information Value (для швидкого порівняння).\n",
    "3. **Мультиваріантний аналіз**\n",
    "   - Univariate logistic regression → багатовимірна логістична модель (з регуляризацією L1/L2)\n",
    "4. **Моделі на деревній основі**\n",
    "   - Random Forest або XGBoost → permutation importance або SHAP values для надійності.\n",
    "5. **Глибинний пошук залежностей** (опційно)\n",
    "   - dCor або MIC для «нетипових» нелінійностей у невеликих підмножинах.\n",
    "\n",
    "Таким чином, **базовий набір** для вашої задачі:\n",
    "- Mann–Whitney + Cohen’s d (числові),\n",
    "- χ² + IV (категоріальні),\n",
    "- univariate AUC,\n",
    "- logistic regression coefficients,\n",
    "- Random Forest/XGBoost importance (з SHAP).\n",
    "\n",
    "За потреби — mutual information та один з general-dependence тестів (dCor/MIC). Це дасть баланс простоти, інтерпретованості та охоплення як лінійних, так і нелінійних впливів."
   ],
   "id": "ec6d113397d31bcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d2ae3e476bf35001"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
